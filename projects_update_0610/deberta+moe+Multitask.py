"""
DeBERTa MoEå¤šä»»åŠ¡å­¦ä¹ è®­ç»ƒè„šæœ¬

ä½¿ç”¨æ–¹æ³•:

1. å•ä»»åŠ¡æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰:
   python train.py --main_task Actionability

2. å¤šä»»åŠ¡æ¨¡å¼:
   python train.py --multi_task --main_task Actionability

3. è‡ªå®šä¹‰å‚æ•°:
   python train.py --multi_task --num_experts 16 --top_k 4 --load_balance_weight 0.01 --batch_size 8

å¤šä»»åŠ¡å­¦ä¹ è¯´æ˜:
- è®­ç»ƒæ—¶åŒæ—¶å­¦ä¹ 4ä¸ªä»»åŠ¡: Actionability, Mistake_Identification, Mistake_Location, Providing_Guidance
- ä½¿ç”¨Uncertainty Weightingè‡ªåŠ¨è°ƒæ•´å„ä»»åŠ¡æŸå¤±æƒé‡
- éªŒè¯æ—¶åªè¯„ä¼°ä¸»ä»»åŠ¡(--main_taskæŒ‡å®š)
- æ¨¡å‹ä¼šè‡ªåŠ¨å­¦ä¹ ä»»åŠ¡é—´çš„å…±äº«è¡¨ç¤ºå’Œä»»åŠ¡ç‰¹å®šè¡¨ç¤º
"""

import os
import json
import torch
import torch.nn as nn
import torch.nn.functional as F
import wandb
import random
import argparse
import numpy as np
from tqdm import tqdm
from transformers import AutoModel, AutoTokenizer, AdamW, AutoConfig
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class BAE2025Dataset(Dataset):
    def __init__(
            self,
            data_path,
            label_type="Actionability",  # ä¸»ä»»åŠ¡ï¼Œç”¨äºéªŒè¯
            labels={
                "Yes": 0,
                "To some extent": 1, 
                "No": 2,
            },
            multi_task=True  # æ˜¯å¦å¯ç”¨å¤šä»»åŠ¡æ¨¡å¼
    ):
        self.data_path = data_path
        self.label_type = label_type
        self.labels = labels
        self.multi_task = multi_task
        self.task_names = ["Actionability", "Mistake_Identification", "Mistake_Location", "Providing_Guidance"]
        self._get_data()
    
    def _get_data(self):
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.data = []
        for item in data:
            # æ–°æ•°æ®æ ¼å¼ï¼šæ¯ä¸ªitemç›´æ¥åŒ…å«conversation_history, responseå’Œ4ä¸ªä»»åŠ¡æ ‡ç­¾
            if 'conversation_history' in item and 'response' in item:
                sent1 = item['conversation_history']
                sent2 = item['response']
                
                if self.multi_task:
                    # å¤šä»»åŠ¡æ¨¡å¼ï¼šæ”¶é›†æ‰€æœ‰4ä¸ªä»»åŠ¡çš„æ ‡ç­¾
                    all_labels = {}
                    valid_sample = True
                    
                    for task_name in self.task_names:
                        if (task_name in item and 
                            item[task_name] in self.labels):
                            all_labels[task_name] = self.labels[item[task_name]]
                        else:
                            valid_sample = False
                            break
                    
                    if valid_sample:
                        self.data.append(((sent1, sent2), all_labels))
                else:
                    # å•ä»»åŠ¡æ¨¡å¼ï¼šåªæ”¶é›†ä¸»ä»»åŠ¡æ ‡ç­¾
                    if (self.label_type in item and 
                        item[self.label_type] in self.labels):
                        self.data.append(((sent1, sent2), self.labels[item[self.label_type]]))
    
    def __len__(self):
        return len(self.data)
    
    def get_labels(self):
        return self.labels

    def __getitem__(self, idx):
        return self.data[idx]


class BAE2025DataLoader:
    def __init__(
        self,
        dataset,
        batch_size=16,
        max_length=512,
        shuffle=True,
        drop_last=True,
        device=None,
        tokenizer_name='/mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base',
        multi_task=False
    ):
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        self.tokenizer.truncation_side = 'left'  # è®¾ç½®æˆªæ–­æ–¹å‘ä¸ºå·¦ä¾§
        self.multi_task = multi_task
        self.task_names = ["Actionability", "Mistake_Identification", "Mistake_Location", "Providing_Guidance"]
        print("å½“å‰ä½¿ç”¨çš„ tokenizer ç±»å‹ï¼š", type(self.tokenizer))
        
        self.dataset = dataset
        self.batch_size = batch_size
        self.max_length = max_length
        self.shuffle = shuffle
        self.drop_last = drop_last

        if device is None:
            self.device = torch.device(
                'cuda' if torch.cuda.is_available() else 'cpu'
            )
        else:
            self.device = device

        self.loader = DataLoader(
            dataset=self.dataset,
            batch_size=self.batch_size,
            collate_fn=self.collate_fn,
            shuffle=self.shuffle,
            drop_last=self.drop_last
        )

    def collate_fn(self, data):
        sents = [i[0] for i in data]
        labels = [i[1] for i in data]

        # å¤„ç†ä¸¤ä¸ªå¥å­çš„æƒ…å†µ
        data = self.tokenizer.batch_encode_plus(
            batch_text_or_text_pairs=[(sent[0], sent[1]) for sent in sents],
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt',
            return_length=True
        )
        input_ids = data['input_ids'].to(self.device)
        attention_mask = data['attention_mask'].to(self.device)
        
        if self.multi_task:
            # å¤šä»»åŠ¡æ¨¡å¼ï¼šå°†æ ‡ç­¾å­—å…¸è½¬æ¢ä¸ºå¼ é‡å­—å…¸
            batch_labels = {}
            for task_name in self.task_names:
                task_labels = [label_dict[task_name] for label_dict in labels]
                batch_labels[task_name] = torch.LongTensor(task_labels).to(self.device)
            return input_ids, attention_mask, batch_labels
        else:
            # å•ä»»åŠ¡æ¨¡å¼
            labels = torch.LongTensor(labels).to(self.device)
            return input_ids, attention_mask, labels

    def __iter__(self):
        for data in self.loader:
            yield data

    def __len__(self):
        return len(self.loader)


class MLPExpert(nn.Module):
    """MLPä¸“å®¶æ¨¡å‹"""
    def __init__(self, input_size, hidden_size, num_layers=2, dropout=0.1):
        super().__init__()
        layers = []
        current_size = input_size
        
        # æ„å»ºå¤šå±‚MLP
        for i in range(num_layers):
            if i == num_layers - 1:  # æœ€åä¸€å±‚
                layers.append(nn.Linear(current_size, hidden_size))
            else:
                layers.append(nn.Linear(current_size, hidden_size))
                layers.append(nn.LayerNorm(hidden_size))
                layers.append(nn.GELU())
                layers.append(nn.Dropout(dropout))
                current_size = hidden_size
                
        self.mlp = nn.Sequential(*layers)
        
    def forward(self, x):
        # x: [batch_size, seq_len, input_size] æˆ– [batch_size, input_size]
        if len(x.shape) == 3:
            # å¦‚æœæ˜¯åºåˆ—è¾“å…¥ï¼Œä½¿ç”¨å¹³å‡æ± åŒ–
            x = torch.mean(x, dim=1)  # [batch_size, input_size]
        return self.mlp(x)  # [batch_size, hidden_size]


class BertClassificationHead(nn.Module):
    def __init__(self, hidden_size=1024, num_classes=3, dropout_prob=0.3):
        super().__init__()
        self.dense = nn.Linear(hidden_size, hidden_size)
        self.dropout = nn.Dropout(dropout_prob)
        self.out_proj = nn.Linear(hidden_size, num_classes)
    
    def forward(self, features):
        # æå– [CLS] æ ‡è®°çš„è¡¨ç¤º
        x = features[:, 0, :]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡è®°([CLS])
        x = self.dropout(x)
        x = self.dense(x)
        x = torch.tanh(x)
        x = self.dropout(x)
        x = self.out_proj(x)
        return x


class DynamicMoERouter(nn.Module):
    """åŠ¨æ€ä¸“å®¶è·¯ç”±å™¨ï¼Œæ”¯æŒtopKé€‰æ‹©"""
    def __init__(self, input_size, num_experts, top_k=2):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = min(top_k, num_experts)  # ç¡®ä¿top_kä¸è¶…è¿‡ä¸“å®¶æ•°é‡
        self.router = nn.Linear(input_size, num_experts)
        
    def forward(self, x):
        # x: [batch_size, input_size]
        batch_size = x.size(0)
        
        # è®¡ç®—è·¯ç”±logits
        router_logits = self.router(x)  # [batch_size, num_experts]
        
        # è®¡ç®—æ‰€æœ‰ä¸“å®¶çš„softmaxæ¦‚ç‡ï¼ˆç”¨äºè´Ÿè½½å‡è¡¡æŸå¤±ï¼‰
        all_probs = F.softmax(router_logits, dim=-1)  # [batch_size, num_experts]
        
        # é€‰æ‹©topKä¸ªä¸“å®¶
        top_k_logits, top_k_indices = torch.topk(router_logits, self.top_k, dim=-1)
        
        # å¯¹é€‰ä¸­çš„ä¸“å®¶åº”ç”¨softmax
        top_k_probs = F.softmax(top_k_logits, dim=-1)  # [batch_size, top_k]
        
        # åˆ›å»ºç¨€ç–çš„è·¯ç”±æƒé‡çŸ©é˜µ
        routing_weights = torch.zeros_like(router_logits)  # [batch_size, num_experts]
        routing_weights.scatter_(1, top_k_indices, top_k_probs)
        
        return routing_weights, top_k_indices, all_probs  # [batch_size, num_experts], [batch_size, top_k], [batch_size, num_experts]


class DeBERTaMoEClassifier(nn.Module):
    def __init__(
        self, 
        pretrained_model_name, 
        num_classes=3, 
        freeze_pooler=0,
        expert_hidden_size=256,
        dropout=0.3,
        num_experts=16,  # æ–°å¢ï¼šä¸“å®¶æ•°é‡
        top_k=4,  # æ–°å¢ï¼šæ¯æ¬¡é€‰æ‹©çš„ä¸“å®¶æ•°é‡
        expert_mlp_layers=2,  # æ–°å¢ï¼šä¸“å®¶MLPå±‚æ•°
        load_balance_weight=0.01,  # æ–°å¢ï¼šè´Ÿè½½å‡è¡¡æŸå¤±æƒé‡
        multi_task=False,  # æ–°å¢ï¼šæ˜¯å¦å¯ç”¨å¤šä»»åŠ¡å­¦ä¹ 
        task_names=None,  # æ–°å¢ï¼šä»»åŠ¡åç§°åˆ—è¡¨
    ):
        super().__init__()
        
        # ä½¿ç”¨ AutoModel åŠ è½½ DeBERTa æ¨¡å‹
        self.bert = AutoModel.from_pretrained(pretrained_model_name)
        
        # è·å– bert éšè—å±‚å¤§å°
        self.bert_hidden_size = self.bert.config.hidden_size
        self.num_experts = num_experts
        self.top_k = top_k
        self.load_balance_weight = load_balance_weight  # è´Ÿè½½å‡è¡¡æŸå¤±æƒé‡
        self.multi_task = multi_task
        
        # è®¾ç½®ä»»åŠ¡åç§°
        if task_names is None:
            self.task_names = ["Actionability", "Mistake_Identification", "Mistake_Location", "Providing_Guidance"]
        else:
            self.task_names = task_names
        
        # ä¿ç•™åŸæœ‰çš„åˆ†ç±»å¤´ï¼ˆç”¨äºå•ä»»åŠ¡æˆ–ä½œä¸ºå…±äº«è¡¨ç¤ºï¼‰
        self.original_classifier = BertClassificationHead(
            hidden_size=self.bert_hidden_size,
            num_classes=num_classes,
            dropout_prob=dropout
        )
        
        # åˆ›å»ºå¤šä¸ªMLPä¸“å®¶
        self.experts = nn.ModuleList([
            MLPExpert(
                input_size=self.bert_hidden_size,
                hidden_size=expert_hidden_size,
                num_layers=expert_mlp_layers,
                dropout=dropout
            ) for _ in range(num_experts)
        ])
        
        # åˆ›å»ºåŠ¨æ€è·¯ç”±å™¨
        self.router = DynamicMoERouter(
            input_size=self.bert_hidden_size, 
            num_experts=num_experts,
            top_k=top_k
        )
        
        # ä¸“å®¶è¾“å‡ºæ˜ å°„å±‚
        self.expert_output_proj = nn.Linear(expert_hidden_size, num_classes)
        
        if self.multi_task:
            # å¤šä»»åŠ¡æ¨¡å¼ï¼šä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºç‹¬ç«‹çš„åˆ†ç±»å¤´
            self.task_classifiers = nn.ModuleDict({
                task_name: nn.Sequential(
                    nn.Linear(num_classes * 2, num_classes * 2 // 2),  # åŸå§‹åˆ†ç±»å¤´ + MoEè¾“å‡º
                    nn.LayerNorm(num_classes * 2 // 2),
                    nn.Dropout(dropout),
                    nn.ReLU(),
                    nn.Linear(num_classes * 2 // 2, num_classes)
                ) for task_name in self.task_names
            })
            
            # è‡ªåŠ¨æƒé‡ç®¡ç† - ä½¿ç”¨Uncertainty Weighting
            # æ¯ä¸ªä»»åŠ¡æœ‰ä¸€ä¸ªå¯å­¦ä¹ çš„log(ÏƒÂ²)å‚æ•°
            self.task_log_vars = nn.Parameter(torch.zeros(len(self.task_names)))
            
        else:
            # å•ä»»åŠ¡æ¨¡å¼ï¼šæœ€ç»ˆçš„èåˆå±‚
            # åŸå§‹åˆ†ç±»å¤´ + MoEè¾“å‡º = 2 * num_classes
            combined_dim = num_classes * 2
            self.final_classifier = nn.Sequential(
                nn.Linear(combined_dim, combined_dim // 2),
                nn.LayerNorm(combined_dim // 2),
                nn.Dropout(dropout),
                nn.ReLU(),
                nn.Linear(combined_dim // 2, num_classes)
            )
    
    def compute_load_balance_loss(self, all_probs, top_k_indices):
        """
        è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±
        
        Args:
            all_probs: [batch_size, num_experts] - æ‰€æœ‰ä¸“å®¶çš„softmaxæ¦‚ç‡
            top_k_indices: [batch_size, top_k] - é€‰ä¸­çš„ä¸“å®¶ç´¢å¼•
            
        Returns:
            load_balance_loss: æ ‡é‡å¼ é‡
        """
        batch_size = all_probs.size(0)
        
        # 1. è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡é€‰æ‹©æ¦‚ç‡ (importance)
        importance = torch.mean(all_probs, dim=0)  # [num_experts]
        
        # 2. è®¡ç®—æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„é¢‘ç‡ (frequency)
        # åˆ›å»ºone-hotç¼–ç çŸ©é˜µè¡¨ç¤ºå“ªäº›ä¸“å®¶è¢«é€‰ä¸­
        selection_mask = torch.zeros_like(all_probs)  # [batch_size, num_experts]
        
        # å°†é€‰ä¸­çš„ä¸“å®¶ä½ç½®è®¾ä¸º1
        for i in range(self.top_k):
            expert_indices = top_k_indices[:, i]  # [batch_size]
            selection_mask.scatter_(1, expert_indices.unsqueeze(1), 1.0)
        
        # è®¡ç®—æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„é¢‘ç‡
        frequency = torch.mean(selection_mask, dim=0)  # [num_experts]
        
        # 3. è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤± (Switch Transformer style)
        # auxiliary_loss = Î± * num_experts * Î£(f_i * P_i)
        # å…¶ä¸­ f_i æ˜¯ä¸“å®¶iè¢«é€‰æ‹©çš„é¢‘ç‡ï¼ŒP_i æ˜¯ä¸“å®¶içš„å¹³å‡é‡è¦æ€§
        auxiliary_loss = self.num_experts * torch.sum(frequency * importance)
        
        # 4. å¯é€‰ï¼šæ·»åŠ æ–¹å·®æŸå¤±æ¥è¿›ä¸€æ­¥é¼“åŠ±å‡åŒ€åˆ†å¸ƒ
        target_frequency = 1.0 / self.num_experts
        frequency_variance = torch.var(frequency)
        importance_variance = torch.var(importance)
        
        # æ€»è´Ÿè½½å‡è¡¡æŸå¤±
        load_balance_loss = auxiliary_loss + frequency_variance + importance_variance
        
        return load_balance_loss
    
    def compute_multi_task_loss(self, task_logits, task_labels):
        """
        ä½¿ç”¨Uncertainty Weightingè®¡ç®—å¤šä»»åŠ¡æŸå¤±
        
        Args:
            task_logits: å­—å…¸ï¼ŒåŒ…å«æ¯ä¸ªä»»åŠ¡çš„logits
            task_labels: å­—å…¸ï¼ŒåŒ…å«æ¯ä¸ªä»»åŠ¡çš„æ ‡ç­¾
            
        Returns:
            total_loss: æ€»æŸå¤±
            task_losses: å„ä»»åŠ¡æŸå¤±å­—å…¸
        """
        task_losses = {}
        total_loss = 0
        
        criterion = nn.CrossEntropyLoss()
        
        for i, task_name in enumerate(self.task_names):
            if task_name in task_logits and task_name in task_labels:
                # è®¡ç®—ä»»åŠ¡æŸå¤±
                task_loss = criterion(task_logits[task_name], task_labels[task_name])
                task_losses[task_name] = task_loss
                
                # ä½¿ç”¨Uncertainty Weighting
                # Loss = (1/2ÏƒÂ²) * L + log(ÏƒÂ²)
                precision = torch.exp(-self.task_log_vars[i])
                weighted_loss = precision * task_loss + self.task_log_vars[i]
                
                total_loss += weighted_loss
        
        return total_loss, task_losses
        
    def forward(self, input_ids, attention_mask, return_loss=True):
        # DeBERTa ç¼–ç 
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        
        # è·å–åºåˆ—éšè—çŠ¶æ€
        hidden_states = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]
        batch_size = hidden_states.size(0)
        
        # è·å–åŸå§‹åˆ†ç±»å¤´ç»“æœ
        original_logits = self.original_classifier(hidden_states)  # [batch_size, num_classes]
        
        # è·å–è·¯ç”±æƒé‡å’Œé€‰ä¸­çš„ä¸“å®¶ç´¢å¼•
        cls_embedding = hidden_states[:, 0]  # [batch_size, hidden_size]
        routing_weights, top_k_indices, all_probs = self.router(cls_embedding)  # è·å–æ‰€æœ‰æ¦‚ç‡ç”¨äºè´Ÿè½½å‡è¡¡æŸå¤±
        
        # MoEå‰å‘ä¼ æ’­
        moe_output = torch.zeros(batch_size, self.expert_output_proj.out_features, device=hidden_states.device)
        
        # åªå¯¹é€‰ä¸­çš„ä¸“å®¶è¿›è¡Œè®¡ç®—
        for i in range(self.top_k):
            # è·å–å½“å‰ä½ç½®æ‰€æœ‰æ ·æœ¬é€‰ä¸­çš„ä¸“å®¶ç´¢å¼•
            expert_idx = top_k_indices[:, i]  # [batch_size]
            
            # ä¸ºæ¯ä¸ªæ ·æœ¬è®¡ç®—å¯¹åº”ä¸“å®¶çš„è¾“å‡º
            for batch_idx in range(batch_size):
                current_expert_idx = expert_idx[batch_idx].item()
                current_weight = routing_weights[batch_idx, current_expert_idx]
                
                # è®¡ç®—ä¸“å®¶è¾“å‡º
                expert_hidden = self.experts[current_expert_idx](hidden_states[batch_idx:batch_idx+1])  # [1, expert_hidden_size]
                expert_logits = self.expert_output_proj(expert_hidden)  # [1, num_classes]
                
                # åŠ æƒç´¯åŠ 
                moe_output[batch_idx] += current_weight * expert_logits.squeeze(0)
        
        # æ‹¼æ¥åŸå§‹åˆ†ç±»å¤´å’ŒMoEè¾“å‡º
        combined_logits = torch.cat([original_logits, moe_output], dim=1)  # [batch_size, 2*num_classes]
        
        if self.multi_task:
            # å¤šä»»åŠ¡æ¨¡å¼ï¼šä¸ºæ¯ä¸ªä»»åŠ¡ç”Ÿæˆé¢„æµ‹
            task_logits = {}
            for task_name in self.task_names:
                task_logits[task_name] = self.task_classifiers[task_name](combined_logits)
            
            # è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±
            if return_loss and self.training:
                load_balance_loss = self.compute_load_balance_loss(all_probs, top_k_indices)
                return {
                    'task_logits': task_logits,
                    'load_balance_loss': load_balance_loss,
                    'routing_weights': routing_weights,
                    'expert_utilization': torch.mean(all_probs, dim=0),  # ä¸“å®¶å¹³å‡åˆ©ç”¨ç‡
                    'task_weights': torch.exp(-self.task_log_vars)  # ä»»åŠ¡æƒé‡ï¼ˆ1/ÏƒÂ²ï¼‰
                }
            else:
                return task_logits
        
        else:
            # å•ä»»åŠ¡æ¨¡å¼ï¼šé€šè¿‡æœ€ç»ˆåˆ†ç±»å™¨è¾“å‡ºæœ€ç»ˆç»“æœ
            final_logits = self.final_classifier(combined_logits)
            
            # è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±
            if return_loss and self.training:
                load_balance_loss = self.compute_load_balance_loss(all_probs, top_k_indices)
                return {
                    'logits': final_logits,
                    'load_balance_loss': load_balance_loss,
                    'routing_weights': routing_weights,
                    'expert_utilization': torch.mean(all_probs, dim=0)  # ä¸“å®¶å¹³å‡åˆ©ç”¨ç‡
                }
            else:
                return final_logits
    
    def get_expert_utilization(self, input_ids, attention_mask):
        """è·å–ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡ï¼Œç”¨äºåˆ†æè´Ÿè½½å‡è¡¡"""
        with torch.no_grad():
            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
            hidden_states = outputs.last_hidden_state
            cls_embedding = hidden_states[:, 0]
            routing_weights, top_k_indices, all_probs = self.router(cls_embedding)
            
            # ç»Ÿè®¡æ¯ä¸ªä¸“å®¶è¢«é€‰ä¸­çš„æ¬¡æ•°
            expert_counts = torch.zeros(self.num_experts)
            for i in range(self.top_k):
                expert_idx = top_k_indices[:, i]
                for idx in expert_idx:
                    expert_counts[idx.item()] += 1
            
            # è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±
            load_balance_loss = self.compute_load_balance_loss(all_probs, top_k_indices)
                    
            result = {
                'expert_counts': expert_counts,
                'routing_weights': routing_weights, 
                'top_k_indices': top_k_indices,
                'all_probs': all_probs,
                'load_balance_loss': load_balance_loss,
                'expert_utilization': torch.mean(all_probs, dim=0)  # ä¸“å®¶å¹³å‡åˆ©ç”¨ç‡
            }
            
            # å¦‚æœæ˜¯å¤šä»»åŠ¡æ¨¡å¼ï¼Œæ·»åŠ ä»»åŠ¡æƒé‡ä¿¡æ¯
            if self.multi_task:
                result['task_weights'] = torch.exp(-self.task_log_vars)
                result['task_log_vars'] = self.task_log_vars
            
            return result


def argparser():
    """å‘½ä»¤è¡Œå‚æ•°è§£æ"""
    parser = argparse.ArgumentParser(description='DeBERTa MoE Training')
    
    # æ¨¡å‹ç›¸å…³å‚æ•°
    parser.add_argument('--model_name', type=str, 
                       default='/mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base',
                       help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--num_classes', type=int, default=3, help='åˆ†ç±»ç±»åˆ«æ•°')
    parser.add_argument('--dropout', type=float, default=0.1, help='Dropoutç‡')
    parser.add_argument('--freeze_pooler', type=int, default=0, help='æ˜¯å¦å†»ç»“poolerå±‚')
    
    # MoEç›¸å…³å‚æ•°
    parser.add_argument('--num_experts', type=int, default=16, help='ä¸“å®¶æ•°é‡')
    parser.add_argument('--top_k', type=int, default=4, help='é€‰æ‹©çš„ä¸“å®¶æ•°é‡')
    parser.add_argument('--expert_mlp_layers', type=int, default=2, help='ä¸“å®¶MLPå±‚æ•°')
    parser.add_argument('--expert_hidden_size', type=int, default=768, help='ä¸“å®¶éšè—å±‚å¤§å°')
    parser.add_argument('--load_balance_weight', type=float, default=0.01, help='è´Ÿè½½å‡è¡¡æŸå¤±æƒé‡')
    
    # å¤šä»»åŠ¡å­¦ä¹ å‚æ•°
    parser.add_argument('--multi_task', action='store_true', default=True, help='å¯ç”¨å¤šä»»åŠ¡å­¦ä¹ ')
    parser.add_argument('--main_task', type=str, default='Actionability', 
                       help='ä¸»ä»»åŠ¡åç§°ï¼ˆç”¨äºéªŒè¯ï¼‰')
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--max_length', type=int, default=512, help='æœ€å¤§åºåˆ—é•¿åº¦')
    parser.add_argument('--lr', type=float, default=3e-5, help='å­¦ä¹ ç‡')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--patience', type=int, default=6, help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--weight_decay', type=float, default=0.01, help='æƒé‡è¡°å‡')
    parser.add_argument('--warmup_ratio', type=float, default=0.1, help='é¢„çƒ­æ¯”ä¾‹')
    
    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--data_path', type=str, default='/mnt/cfs/huangzhiwei/Data_mining_BAE2025/data_new/train.json', help='è®­ç»ƒæ•°æ®è·¯å¾„')
    parser.add_argument('--val_data_path', type=str, default='/mnt/cfs/huangzhiwei/Data_mining_BAE2025/data_new/val.json', help='éªŒè¯æ•°æ®è·¯å¾„')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--device', type=str, default=None, help='è®¾å¤‡')
    parser.add_argument('--name', type=str, default=None, help='å®éªŒåç§°')
    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints_track4', help='æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•')
    
    return parser.parse_args()





def train(configs):
    # è®¾ç½®éšæœºç§å­
    random.seed(configs.seed)
    np.random.seed(configs.seed)
    torch.manual_seed(configs.seed)
    
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dir = os.path.join(configs.checkpoint_dir, configs.exp_name)
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # ä¸ºä¿å­˜æ··æ·†çŸ©é˜µåˆ›å»ºç›®å½• - åˆ†åˆ«ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ›å»º
    train_plot_dir = os.path.join(checkpoint_dir, 'plots', 'train')
    val_plot_dir = os.path.join(checkpoint_dir, 'plots', 'val')
    os.makedirs(train_plot_dir, exist_ok=True)
    os.makedirs(val_plot_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®é›†
    train_dataset = BAE2025Dataset(
        configs.data_path, 
        label_type=configs.main_task,
        multi_task=configs.multi_task
    )
    val_dataset = BAE2025Dataset(
        configs.val_data_path, 
        label_type=configs.main_task,
        multi_task=False  # éªŒè¯æ—¶åªä½¿ç”¨ä¸»ä»»åŠ¡
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataloader = BAE2025DataLoader(
        dataset=train_dataset,
        batch_size=configs.batch_size,
        max_length=configs.max_length,
        shuffle=True,
        drop_last=True,
        device=configs.device,
        tokenizer_name=configs.model_name,
        multi_task=configs.multi_task
    )

    val_dataloader = BAE2025DataLoader(
        dataset=val_dataset,
        batch_size=configs.batch_size,
        max_length=configs.max_length,
        shuffle=False,
        drop_last=False,
        device=configs.device,
        tokenizer_name=configs.model_name,
        multi_task=False  # éªŒè¯æ—¶ä½¿ç”¨å•ä»»åŠ¡æ¨¡å¼
    )
    
    # åˆ›å»ºMoEæ¨¡å‹
    model = DeBERTaMoEClassifier(
        pretrained_model_name=configs.model_name,
        num_classes=configs.num_classes,
        freeze_pooler=configs.freeze_pooler,
        expert_hidden_size=configs.expert_hidden_size,
        dropout=configs.dropout,
        num_experts=configs.num_experts,
        top_k=configs.top_k,
        expert_mlp_layers=configs.expert_mlp_layers,
        load_balance_weight=configs.load_balance_weight,
        multi_task=configs.multi_task
    ).to(configs.device)

    criterion = nn.CrossEntropyLoss()

    # å®šä¹‰ä¼˜åŒ–å™¨
    optimizer = AdamW(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=configs.lr,
        weight_decay=configs.weight_decay
    )
    
    # åˆå§‹åŒ–æœ€ä½³éªŒè¯æŸå¤±å’Œæ—©åœè®¡æ•°å™¨
    best_val_acc = 0.0
    best_val_f1 = 0.0  # æ·»åŠ F1åˆ†æ•°ä½œä¸ºè¯„ä¼°æŒ‡æ ‡
    best_val_loss = float('inf')
    patience_counter = 0
    
    # åˆå§‹åŒ–æœ€ä½³æŒ‡æ ‡è®°å½•
    best_metrics = {
        'epoch': 0,
        'val_f1': 0.0,
        'val_acc': 0.0,
        'val_loss': float('inf')
    }

    # å®šä¹‰ç±»åˆ«åç§°
    class_names = ['Yes', 'To some extent', 'No']
    task_names = ["Actionability", "Mistake_Identification", "Mistake_Location", "Providing_Guidance"]
    
    if configs.multi_task:
        print(f"ğŸ¯ å¼€å§‹å¤šä»»åŠ¡è®­ç»ƒ!")
        print(f"è®­ç»ƒä»»åŠ¡: {task_names}")
        print(f"ä¸»ä»»åŠ¡ (éªŒè¯): {configs.main_task}")
    else:
        print(f"ğŸ¯ å¼€å§‹å•ä»»åŠ¡è®­ç»ƒ!")
        print(f"ä»»åŠ¡: {configs.main_task}")
    
    print(f"ä¸“å®¶æ•°é‡: {configs.num_experts}, Top-K: {configs.top_k}")
    print(f"è´Ÿè½½å‡è¡¡æƒé‡: {configs.load_balance_weight}")
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(configs.epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_load_balance_loss = 0.0
        train_acc = 0.0
        train_preds = []
        train_labels_list = []
        
        # å¤šä»»åŠ¡è®­ç»ƒæ—¶çš„ä»»åŠ¡æŸå¤±ç»Ÿè®¡
        if configs.multi_task:
            task_losses_sum = {task_name: 0.0 for task_name in task_names}
            task_accs = {task_name: 0.0 for task_name in task_names}
            task_preds = {task_name: [] for task_name in task_names}
            task_labels = {task_name: [] for task_name in task_names}
        
        with tqdm(
            train_dataloader,
            total=len(train_dataloader),
            desc=f'Epoch {epoch + 1}/{configs.epochs}',
            unit='batch',
            ncols=140
        ) as pbar:
            for batch_data in pbar:
                optimizer.zero_grad()
                
                if configs.multi_task:
                    input_ids, attention_mask, labels_dict = batch_data
                    
                    # å‰å‘ä¼ æ’­ - è·å–å¤šä»»åŠ¡MoEè¾“å‡º
                    outputs = model(input_ids, attention_mask, return_loss=True)
                    
                    task_logits = outputs['task_logits']
                    load_balance_loss = outputs['load_balance_loss']
                    task_weights = outputs.get('task_weights', None)
                    
                    # è®¡ç®—å¤šä»»åŠ¡æŸå¤±
                    multi_task_loss, individual_task_losses = model.compute_multi_task_loss(task_logits, labels_dict)
                    
                    # æ€»æŸå¤± = å¤šä»»åŠ¡æŸå¤± + è´Ÿè½½å‡è¡¡æŸå¤±
                    total_loss = multi_task_loss + model.load_balance_weight * load_balance_loss
                    
                    # ç»Ÿè®¡å„ä»»åŠ¡çš„å‡†ç¡®ç‡å’ŒæŸå¤±
                    for task_name in task_names:
                        if task_name in task_logits and task_name in labels_dict:
                            task_pred = task_logits[task_name].argmax(dim=1)
                            task_label = labels_dict[task_name].long()
                            
                            task_acc = (task_pred == task_label).float().sum()
                            task_accs[task_name] += task_acc.item()
                            task_losses_sum[task_name] += individual_task_losses[task_name].item()
                            
                            # æ”¶é›†ä¸»ä»»åŠ¡çš„é¢„æµ‹ç»“æœç”¨äºF1è®¡ç®—
                            if task_name == configs.main_task:
                                train_preds.extend(task_pred.cpu().numpy())
                                train_labels_list.extend(task_label.cpu().numpy())
                    
                    train_loss += multi_task_loss.item()
                    
                else:
                    input_ids, attention_mask, labels = batch_data
                    
                    # å‰å‘ä¼ æ’­ - è·å–å•ä»»åŠ¡MoEè¾“å‡º
                    outputs = model(input_ids, attention_mask, return_loss=True)
                    
                    if isinstance(outputs, dict):
                        logits = outputs['logits']
                        load_balance_loss = outputs['load_balance_loss']
                    else:
                        logits = outputs
                        load_balance_loss = torch.tensor(0.0, device=logits.device)
                    
                    # è®¡ç®—åˆ†ç±»æŸå¤±
                    labels = labels.long()
                    classification_loss = criterion(logits, labels)
                    
                    # æ€»æŸå¤± = åˆ†ç±»æŸå¤± + è´Ÿè½½å‡è¡¡æŸå¤±
                    total_loss = classification_loss + model.load_balance_weight * load_balance_loss
                    
                    preds = logits.argmax(dim=1)
                    accuracy = (preds == labels).float().mean()
                    accuracy_all = (preds == labels).float().sum()
                    
                    # æ”¶é›†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼Œç”¨äºè®¡ç®—F1
                    train_preds.extend(preds.cpu().numpy())
                    train_labels_list.extend(labels.cpu().numpy())
                    
                    train_loss += classification_loss.item()
                    train_acc += accuracy_all.item()
                
                # åå‘ä¼ æ’­
                total_loss.backward()
                optimizer.step()
                
                train_load_balance_loss += load_balance_loss.item()
                
                # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                if configs.multi_task:
                    # æ˜¾ç¤ºä¸»ä»»åŠ¡çš„æŸå¤±å’Œæƒé‡ä¿¡æ¯
                    main_task_loss = individual_task_losses.get(configs.main_task, torch.tensor(0.0))
                    pbar.set_postfix(
                        mt_loss=f'{multi_task_loss.item():.3f}',
                        main_loss=f'{main_task_loss.item():.3f}',
                        lb_loss=f'{load_balance_loss.item():.4f}'
                    )
                else:
                    pbar.set_postfix(
                        cls_loss=f'{classification_loss.item():.3f}',
                        lb_loss=f'{load_balance_loss.item():.4f}',
                        acc=f'{accuracy.item():.3f}'
                    )
        
        train_loss = train_loss / len(train_dataloader)
        train_load_balance_loss = train_load_balance_loss / len(train_dataloader)
        
        if configs.multi_task:
            # è®¡ç®—å„ä»»åŠ¡çš„å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
            for task_name in task_names:
                task_losses_sum[task_name] = task_losses_sum[task_name] / len(train_dataloader)
                task_accs[task_name] = task_accs[task_name] / len(train_dataset)
            
            # è®¡ç®—ä¸»ä»»åŠ¡çš„F1åˆ†æ•°
            train_f1 = f1_score(train_labels_list, train_preds, average='macro')
            
            print(f'Training - Multi-task Loss: {train_loss:.4f}, Load Balance Loss: {train_load_balance_loss:.4f}')
            print(f'Training - Main Task ({configs.main_task}) F1: {train_f1:.4f}')
            
            # æ˜¾ç¤ºä»»åŠ¡æƒé‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'task_weights' in outputs:
                task_weights_str = ', '.join([f'{task}: {weight:.3f}' for task, weight in 
                                            zip(task_names, outputs['task_weights'].detach().cpu().numpy())])
                print(f'Task Weights: {task_weights_str}')
            
        else:
            train_acc = train_acc / len(train_dataset)
            train_f1 = f1_score(train_labels_list, train_preds, average='macro')
            
            print(f'Training - Classification Loss: {train_loss:.4f}, Load Balance Loss: {train_load_balance_loss:.4f}')
            print(f'Training - Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}')
        
        # éªŒè¯é˜¶æ®µ (å§‹ç»ˆä½¿ç”¨ä¸»ä»»åŠ¡è¿›è¡ŒéªŒè¯)
        model.eval()
        val_loss = 0.0
        val_corrects = 0.0
        val_preds = []
        val_labels_list = []

        with torch.no_grad():
            for input_ids, attention_mask, labels in val_dataloader:
                # ç¡®ä¿labelsæ˜¯é•¿æ•´å‹
                labels = labels.long()
                
                if configs.multi_task:
                    # å¤šä»»åŠ¡æ¨¡å¼ï¼šåªå–ä¸»ä»»åŠ¡çš„é¢„æµ‹ç»“æœ
                    task_logits = model(input_ids, attention_mask, return_loss=False)
                    logits = task_logits[configs.main_task]
                else:
                    # å•ä»»åŠ¡æ¨¡å¼
                    logits = model(input_ids, attention_mask, return_loss=False)
                
                loss = criterion(logits, labels)
                val_loss += loss.item()
                preds = logits.argmax(dim=1)
                accuracy = (preds == labels).float().sum()
                val_corrects += accuracy
                
                # æ”¶é›†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼Œç”¨äºè®¡ç®—F1å’Œæ··æ·†çŸ©é˜µ
                val_preds.extend(preds.cpu().numpy())
                val_labels_list.extend(labels.cpu().numpy())
        
        val_loss = val_loss / len(val_dataloader)
        val_acc = val_corrects.double() / len(val_dataset)
        
        # è®¡ç®—éªŒè¯é›†çš„F1åˆ†æ•°
        val_f1 = f1_score(val_labels_list, val_preds, average='macro')
        
        print(f'Validation ({configs.main_task}) - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}')

        # åˆ†æä¸“å®¶ä½¿ç”¨æƒ…å†µï¼ˆå¯é€‰ï¼Œä»…åœ¨æŸäº›epochæ‰§è¡Œä»¥èŠ‚çœæ—¶é—´ï¼‰
        if epoch % 5 == 0:  # æ¯5ä¸ªepochåˆ†æä¸€æ¬¡
            # ä½¿ç”¨éªŒè¯é›†çš„ä¸€ä¸ªbatchæ¥åˆ†æä¸“å®¶ä½¿ç”¨
            sample_input_ids, sample_attention_mask, _ = next(iter(val_dataloader))
            expert_stats = model.get_expert_utilization(sample_input_ids, sample_attention_mask)
            expert_counts = expert_stats['expert_counts']
            expert_utilization = expert_stats['expert_utilization']
            
            print(f"ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡ (Epoch {epoch+1}):")
            print(f"  ä¸“å®¶é€‰æ‹©æ¬¡æ•°: {expert_counts.numpy()}")
            print(f"  ä¸“å®¶å¹³å‡åˆ©ç”¨ç‡: {expert_utilization.cpu().numpy()}")
            print(f"  åˆ©ç”¨ç‡æ ‡å‡†å·®: {torch.std(expert_utilization).item():.4f}")
            
            # æ˜¾ç¤ºå¤šä»»åŠ¡æƒé‡ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
            if configs.multi_task and 'task_weights' in expert_stats:
                task_weights = expert_stats['task_weights']
                task_weights_str = ', '.join([f'{task}: {weight:.3f}' for task, weight in 
                                            zip(task_names, task_weights.detach().cpu().numpy())])
                print(f"  ä»»åŠ¡æƒé‡: {task_weights_str}")
        
        # æ£€æŸ¥æ˜¯å¦ä¿å­˜æ¨¡å‹å¹¶åˆ¤æ–­æ˜¯å¦éœ€è¦æ—©åœ
        # ä½¿ç”¨F1åˆ†æ•°ä½œä¸ºä¸»è¦æŒ‡æ ‡
        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
            best_val_acc = val_acc
            best_val_loss = val_loss
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            # state_dict = model.state_dict()
            # model_name = 'best_model_multi_task.pt' if configs.multi_task else 'best_model_f1.pt'
            # torch.save(state_dict, os.path.join(checkpoint_dir, model_name))
            print(f'ğŸ‰ New best model saved! F1: {best_val_f1:.4f}, Acc: {best_val_acc:.4f}')
            
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= configs.patience:
                print(f'ğŸ›‘ Early stopping triggered after {epoch+1} epochs.')
                break

        model.train()

    print("ğŸŠ è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³ç»“æœ ({configs.main_task}) - F1: {best_val_f1:.4f}, Acc: {best_val_acc:.4f}, Loss: {best_val_loss:.4f}")


# ä¸»å‡½æ•°
if __name__ == '__main__':
    # ä½¿ç”¨argparseè§£æå‘½ä»¤è¡Œå‚æ•°
    configs = argparser()
    
    # è®¾ç½®å®éªŒåç§°
    if configs.name is None:
        exp_name_parts = [
            f'{os.path.basename(configs.model_name)}',
            f'{"_mt" if configs.multi_task else ""}',  # å¤šä»»åŠ¡æ ‡è¯†
            f'{"_fp" if configs.freeze_pooler else ""}',
            f'_moe{configs.num_experts}k{configs.top_k}',
            f'_b{configs.batch_size}_e{configs.epochs}',
            f'_len{configs.max_length}_lr{configs.lr}'
        ]
        configs.exp_name = ''.join(exp_name_parts)
    else:
        configs.exp_name = configs.name
    
    # è®¾ç½®è®¾å¤‡
    if configs.device is None:
        configs.device = torch.device(
            'cuda' if torch.cuda.is_available() else 'cpu'
        )
    
    print(f"ä½¿ç”¨è®¾å¤‡: {configs.device}")
    print(f"å®éªŒåç§°: {configs.exp_name}")
    
    if configs.multi_task:
        print(f"ğŸ¯ å¤šä»»åŠ¡å­¦ä¹ æ¨¡å¼")
        print(f"ä¸»ä»»åŠ¡: {configs.main_task}")
    else:
        print(f"ğŸ¯ å•ä»»åŠ¡å­¦ä¹ æ¨¡å¼")
        print(f"ä»»åŠ¡: {configs.main_task}")
    
    # è°ƒç”¨è®­ç»ƒå‡½æ•°
    train(configs)