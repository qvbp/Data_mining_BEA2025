{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取原始数据文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train.json') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "# 创建一个列表来存储所有的 conversation_history\n",
    "conversation_history_list = []\n",
    "\n",
    "# 提取每个 data 中的 conversation_history\n",
    "for data in datas:\n",
    "    conversation_history_list.append(data['conversation_history'])\n",
    "\n",
    "# 将提取出来的 conversation_history 列表写入到新的 JSON 文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/conversation_history_train.json', 'w') as f:\n",
    "    json.dump(conversation_history_list, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取原始数据文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid.json') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "# 创建一个列表来存储所有的 conversation_history\n",
    "conversation_history_list = []\n",
    "\n",
    "# 提取每个 data 中的 conversation_history\n",
    "for data in datas:\n",
    "    conversation_history_list.append(data['conversation_history'])\n",
    "\n",
    "# 将提取出来的 conversation_history 列表写入到新的 JSON 文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/conversation_history_valid.json', 'w') as f:\n",
    "    json.dump(conversation_history_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 合并json数据，生成新的json文件\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 读取第一个JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/new_no_to-some-extent_train.json', 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "    \n",
    "# 读取第二个JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train.json', 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "    \n",
    "# 合并数据, data1和data2的内容是列表\n",
    "merged_data = data1 + data2\n",
    "\n",
    "# 将合并后的数据写入新的JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train_extend.json', 'w') as f:\n",
    "    json.dump(merged_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 合并json数据，生成新的json文件\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 读取第一个JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/new_no_to-some-extent_val.json', 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "    \n",
    "# 读取第二个JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid.json', 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "    \n",
    "# 合并数据, data1和data2的内容是列表\n",
    "merged_data = data1 + data2\n",
    "\n",
    "# 将合并后的数据写入新的JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid_extend.json', 'w') as f:\n",
    "    json.dump(merged_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providing Guidance Counts: {'No': 931, 'Yes': 1107, 'To some extent': 1137}\n"
     ]
    }
   ],
   "source": [
    "# check一下对应标签的数量\n",
    "\n",
    "import json\n",
    "\n",
    "# 打开json文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train_extend.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "annotations = []\n",
    "for data in datas:\n",
    "    tutor_responses = data['tutor_responses']\n",
    "    for tutor_response in tutor_responses.values():  # Use .values() to access the response dict  用.values()访问响应字典\n",
    "        annotation = tutor_response['annotation']  # Safely access 'annotation'\n",
    "        if isinstance(annotation, dict):  # Check if 'annotation' is a dictionary\n",
    "            annotations.append(annotation)\n",
    "\n",
    "# Collect the values for each category\n",
    "# Mistake_Identification = [annotation['Mistake_Identification'] for annotation in annotations]\n",
    "# Mistake_Location = [annotation['Mistake_Location'] for annotation in annotations]\n",
    "Providing_Guidance = [annotation['Providing_Guidance'] for annotation in annotations]\n",
    "# Actionability = [annotation['Actionability'] for annotation in annotations]\n",
    "\n",
    "# Count occurrences of each value\n",
    "# mistake_identification_counts = {value: Mistake_Identification.count(value) for value in set(Mistake_Identification)}\n",
    "# mistake_location_counts = {value: Mistake_Location.count(value) for value in set(Mistake_Location)}\n",
    "providing_guidance_counts = {value: Providing_Guidance.count(value) for value in set(Providing_Guidance)}\n",
    "# actionability_counts = {value: Actionability.count(value) for value in set(Actionability)}\n",
    "\n",
    "# 输出看一下详细情况\n",
    "# print(\"Mistake Identification Counts:\", mistake_identification_counts)\n",
    "# print(\"Mistake Location Counts:\", mistake_location_counts)\n",
    "print(\"Providing Guidance Counts:\", providing_guidance_counts)\n",
    "# print(\"Actionability Counts:\", actionability_counts)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providing Guidance Counts: {'No': 257, 'Yes': 300, 'To some extent': 236}\n"
     ]
    }
   ],
   "source": [
    "# check一下对应标签的数量\n",
    "\n",
    "import json\n",
    "\n",
    "# 打开json文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid_extend.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "annotations = []\n",
    "for data in datas:\n",
    "    tutor_responses = data['tutor_responses']\n",
    "    for tutor_response in tutor_responses.values():  # Use .values() to access the response dict  用.values()访问响应字典\n",
    "        annotation = tutor_response['annotation']  # Safely access 'annotation'\n",
    "        if isinstance(annotation, dict):  # Check if 'annotation' is a dictionary\n",
    "            annotations.append(annotation)\n",
    "\n",
    "# Collect the values for each category\n",
    "# Mistake_Identification = [annotation['Mistake_Identification'] for annotation in annotations]\n",
    "# Mistake_Location = [annotation['Mistake_Location'] for annotation in annotations]\n",
    "Providing_Guidance = [annotation['Providing_Guidance'] for annotation in annotations]\n",
    "# Actionability = [annotation['Actionability'] for annotation in annotations]\n",
    "\n",
    "# Count occurrences of each value\n",
    "# mistake_identification_counts = {value: Mistake_Identification.count(value) for value in set(Mistake_Identification)}\n",
    "# mistake_location_counts = {value: Mistake_Location.count(value) for value in set(Mistake_Location)}\n",
    "providing_guidance_counts = {value: Providing_Guidance.count(value) for value in set(Providing_Guidance)}\n",
    "# actionability_counts = {value: Actionability.count(value) for value in set(Actionability)}\n",
    "\n",
    "# 输出看一下详细情况\n",
    "# print(\"Mistake Identification Counts:\", mistake_identification_counts)\n",
    "# print(\"Mistake Location Counts:\", mistake_location_counts)\n",
    "print(\"Providing Guidance Counts:\", providing_guidance_counts)\n",
    "# print(\"Actionability Counts:\", actionability_counts)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并两个json文件\n",
    "import json\n",
    "import os\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train.json', 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/r1_merged_math_dialogues_20250404164635.json', 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "    \n",
    "# 合并数据\n",
    "merged_data = data1 + data2\n",
    "# 将合并后的数据写入新的JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train_merged_r1.json', 'w') as f:\n",
    "    json.dump(merged_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并第一次新增模型错误的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json\", 'r', encoding='utf-8') as f:\n",
    "    data1 = json.load(f)\n",
    "    \n",
    "with open(\"/mnt/cfs/huangzhiwei/BAE2025/data/error_1_8+8.json\", 'r', encoding='utf-8') as f:\n",
    "    data2 = json.load(f)\n",
    "    \n",
    "# 合并数据\n",
    "merged_data = data1 + data2\n",
    "\n",
    "# 将合并后的数据写入新的JSON文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/extend_1_8+8.json', 'w') as f:\n",
    "    json.dump(merged_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import string\n",
    "\n",
    "# 读取原始数据文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/extend_1_8+8.json', 'r') as f:\n",
    "    datas = json.load(f)\n",
    "    \n",
    "# 收集所有现有ID\n",
    "existing_ids = []\n",
    "for data in datas:\n",
    "    if \"conversation_id\" in data and data[\"conversation_id\"] is not None:\n",
    "        existing_ids.append(data[\"conversation_id\"])\n",
    "        \n",
    "# 为没有conversation_id的对话生成唯一ID\n",
    "for data in datas:\n",
    "    if \"conversation_id\" not in data or data[\"conversation_id\"] is None:\n",
    "        # 生成8位随机ID（字母+数字）\n",
    "        while True:\n",
    "            new_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "            if new_id not in existing_ids:\n",
    "                data[\"conversation_id\"] = new_id\n",
    "                existing_ids.append(new_id)\n",
    "                break\n",
    "        \n",
    "# 将修改后的数据写入新文件（建议不要直接覆盖原文件）\n",
    "output_path = '/mnt/cfs/huangzhiwei/BAE2025/data_extend/extend_1_8+8.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(datas, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
