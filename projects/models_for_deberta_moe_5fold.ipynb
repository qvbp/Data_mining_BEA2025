{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 设置环境变量，只让程序看到 GPU 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, AutoModel\n",
    "from transformers import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "class BAE2025Dataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path,\n",
    "            label_type=\"Actionability\",  # 根据需要可以是 \"Mistake_Identification\", \"Mistake_Location\", \"Providing_Guidance\", \"Actionability\"\n",
    "            labels={\n",
    "                \"Yes\": 0,\n",
    "                \"To some extent\": 1, \n",
    "                \"No\": 2,\n",
    "            }\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.label_type = label_type\n",
    "        self.labels = labels\n",
    "    #     self._get_data()\n",
    "\n",
    "        self.data = []  # 初始化为空列表\n",
    "        \n",
    "        # 只有在data_path不为None时才加载数据\n",
    "        if self.data_path is not None:\n",
    "            self._get_data()\n",
    "    \n",
    "    def _get_data(self):\n",
    "        with open(self.data_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.data = []\n",
    "        for item in data:\n",
    "            sent1 = item['conversation_history']\n",
    "            sent2 = item['response']\n",
    "            \n",
    "            # 检查item中是否直接包含我们需要的标签\n",
    "            if self.label_type in item and item[self.label_type] in self.labels:\n",
    "                self.data.append(((sent1, sent2), self.labels[item[self.label_type]]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "from transformers import DebertaV2Tokenizer\n",
    "\n",
    "class BAE2025DataLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        max_length=512,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        device=None,\n",
    "        # tokenizer_name='chinese-bert-wwm-ext'\n",
    "        # tokenizer_name='chinese-roberta-wwm-ext'\n",
    "        # tokenizer_name='chinese-roberta-wwm-ext-large'\n",
    "        # tokenizer_name='/mnt/cfs/huangzhiwei/pykt-moekt/SBM/bge-large-en-v1.5'\n",
    "        tokenizer_name='/mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base'\n",
    "        # tokenizer_name='/mnt/cfs/huangzhiwei/BAE2025/models/roberta-base'\n",
    "    ):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.tokenizer.truncation_side = 'left'  # 设置截断方向为左侧,即从句子开头开始截断,假设一个句子过长，则从句子开头开始截断，保留句子结尾的部分\n",
    "        print(\"当前使用的 tokenizer 类型：\", type(self.tokenizer))\n",
    "        \n",
    "        # config = AutoConfig.from_pretrained(tokenizer_name)\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, config=config, use_fast=True)\n",
    "        \n",
    "        \n",
    "        # self.tokenizer = DebertaV2Tokenizer.from_pretrained(tokenizer_name)\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\n",
    "                'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            )\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.loader = DataLoader(\n",
    "            dataset=self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=self.collate_fn,\n",
    "            shuffle=self.shuffle,\n",
    "            drop_last=self.drop_last\n",
    "        )\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        sents = [i[0] for i in data]\n",
    "        labels = [i[1] for i in data]\n",
    "\n",
    "        # 修改这里，处理两个句子的情况\n",
    "        data = self.tokenizer.batch_encode_plus(\n",
    "            batch_text_or_text_pairs=[(sent[0], sent[1]) for sent in sents],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "            return_length=True\n",
    "        )\n",
    "        input_ids = data['input_ids'].to(self.device)\n",
    "        attention_mask = data['attention_mask'].to(self.device)\n",
    "        # token_type_ids = data['token_type_ids'].to(self.device)\n",
    "        labels = torch.LongTensor(labels).to(self.device)\n",
    "\n",
    "        # return input_ids, attention_mask, token_type_ids, labels\n",
    "        return input_ids, attention_mask, labels\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data in self.loader:\n",
    "            yield data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class ExpertLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        output, (hidden, _) = self.lstm(x)\n",
    "        # 返回最后一个时间步的隐藏状态\n",
    "        return hidden[-1]  # [batch_size, hidden_size]\n",
    "\n",
    "\n",
    "class ExpertBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size // 2,  # 因为是双向的，所以每个方向的隐藏层大小减半\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        output, (hidden, _) = self.bilstm(x)\n",
    "        # 拼接最后一层的正向和反向隐藏状态\n",
    "        # hidden shape: [num_layers * num_directions, batch_size, hidden_size//2]\n",
    "        hidden_forward = hidden[-2]  # 正向的最后一层 [batch_size, hidden_size//2]\n",
    "        hidden_backward = hidden[-1]  # 反向的最后一层 [batch_size, hidden_size//2]\n",
    "        hidden_concat = torch.cat([hidden_forward, hidden_backward], dim=1)  # [batch_size, hidden_size]\n",
    "        return hidden_concat\n",
    "\n",
    "\n",
    "class ExpertRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        _, hidden = self.rnn(x)\n",
    "        # 返回最后一个时间步的隐藏状态\n",
    "        return hidden[-1]  # [batch_size, hidden_size]\n",
    "\n",
    "\n",
    "class ExpertGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        _, hidden = self.gru(x)\n",
    "        # 返回最后一个时间步的隐藏状态\n",
    "        return hidden[-1]  # [batch_size, hidden_size]\n",
    "\n",
    "\n",
    "class ExpertLinear(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.LayerNorm(hidden_size * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_size * 2, hidden_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        # 我们需要把序列信息压缩为一个向量，可以使用平均池化\n",
    "        pooled = torch.mean(x, dim=1)  # [batch_size, input_size]\n",
    "        return self.linear(pooled)  # [batch_size, hidden_size]\n",
    "\n",
    "\n",
    "class BertClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size=1024, num_classes=3, dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.out_proj = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        # 提取 [CLS] 标记的表示\n",
    "        x = features[:, 0, :]  # 使用第一个标记([CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MoERouter(nn.Module):\n",
    "    \"\"\"专家路由器，学习为每个样本分配专家权重\"\"\"\n",
    "    def __init__(self, input_size, num_experts):\n",
    "        super().__init__()\n",
    "        self.router = nn.Linear(input_size, num_experts)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, input_size]\n",
    "        # 计算每个专家的权重 (使用softmax确保权重和为1)\n",
    "        router_logits = self.router(x)\n",
    "        router_probs = F.softmax(router_logits, dim=-1)\n",
    "        return router_probs  # [batch_size, num_experts]\n",
    "\n",
    "\n",
    "class DeBERTaMoEClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        pretrained_model_name, \n",
    "        num_classes=3, \n",
    "        freeze_pooler=0,\n",
    "        expert_hidden_size=256,\n",
    "        dropout=0.3,\n",
    "        num_rnn_layers=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 使用 AutoModel 加载 DeBERTa 模型\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        # 获取 bert 隐藏层大小\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # 保留原有的分类头\n",
    "        self.original_classifier = BertClassificationHead(\n",
    "            hidden_size=self.bert_hidden_size,\n",
    "            num_classes=num_classes,\n",
    "            dropout_prob=dropout\n",
    "        )\n",
    "        \n",
    "        # 创建多个专家模型\n",
    "        self.experts = nn.ModuleDict({\n",
    "            'lstm': ExpertLSTM(\n",
    "                input_size=self.bert_hidden_size, \n",
    "                hidden_size=expert_hidden_size,\n",
    "                num_layers=num_rnn_layers,\n",
    "                dropout=dropout\n",
    "            ),\n",
    "            'bilstm': ExpertBiLSTM(\n",
    "                input_size=self.bert_hidden_size, \n",
    "                hidden_size=expert_hidden_size,\n",
    "                num_layers=num_rnn_layers,\n",
    "                dropout=dropout\n",
    "            ),\n",
    "            'rnn': ExpertRNN(\n",
    "                input_size=self.bert_hidden_size, \n",
    "                hidden_size=expert_hidden_size,\n",
    "                num_layers=num_rnn_layers,\n",
    "                dropout=dropout\n",
    "            ),\n",
    "            'gru': ExpertGRU(\n",
    "                input_size=self.bert_hidden_size, \n",
    "                hidden_size=expert_hidden_size,\n",
    "                num_layers=num_rnn_layers,\n",
    "                dropout=dropout\n",
    "            ),\n",
    "            'linear': ExpertLinear(\n",
    "                input_size=self.bert_hidden_size, \n",
    "                hidden_size=expert_hidden_size\n",
    "            ),\n",
    "        })\n",
    "        \n",
    "        # 创建路由器 (使用[CLS]标记表示作为路由的输入)\n",
    "        self.router = MoERouter(self.bert_hidden_size, len(self.experts))\n",
    "        \n",
    "        # 各专家模型的输出映射层，将各自的hidden_size映射到统一的输出空间\n",
    "        self.expert_outputs = nn.ModuleDict({\n",
    "            expert_name: nn.Linear(expert_hidden_size, num_classes)\n",
    "            for expert_name in self.experts.keys()\n",
    "        })\n",
    "        \n",
    "        # 最终的融合层，将所有结果拼接后映射到输出类别\n",
    "        # (1个原始分类头 + 5个专家) * 每个输出num_classes = 6 * num_classes\n",
    "        combined_dim = num_classes * (1 + len(self.experts))\n",
    "        self.final_classifier = nn.Sequential(\n",
    "            nn.Linear(combined_dim, combined_dim // 2),\n",
    "            nn.LayerNorm(combined_dim // 2),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(combined_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # DeBERTa 编码\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # 获取序列隐藏状态\n",
    "        hidden_states = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        # 获取原始分类头结果\n",
    "        original_logits = self.original_classifier(hidden_states)  # [batch_size, num_classes]\n",
    "        \n",
    "        # 获取路由权重\n",
    "        cls_embedding = hidden_states[:, 0]  # [batch_size, hidden_size]\n",
    "        routing_weights = self.router(cls_embedding)  # [batch_size, num_experts]\n",
    "        \n",
    "        # 获取各专家结果\n",
    "        expert_outputs = {}\n",
    "        for expert_name, expert in self.experts.items():\n",
    "            # 获取专家输出\n",
    "            expert_hidden = expert(hidden_states)  # [batch_size, expert_hidden_size]\n",
    "            # 映射到类别空间\n",
    "            expert_logits = self.expert_outputs[expert_name](expert_hidden)  # [batch_size, num_classes]\n",
    "            # 存储结果\n",
    "            expert_outputs[expert_name] = expert_logits\n",
    "        \n",
    "        # 根据路由权重加权专家结果\n",
    "        # 首先，将所有专家的结果拼接到一起\n",
    "        expert_logits_list = [original_logits]  # 包含原始分类头\n",
    "        expert_names = list(self.experts.keys())\n",
    "        \n",
    "        for expert_name in expert_names:\n",
    "            expert_logits_list.append(expert_outputs[expert_name])\n",
    "        \n",
    "        # 拼接所有结果 [batch_size, (1+num_experts)*num_classes]\n",
    "        combined_logits = torch.cat(expert_logits_list, dim=1)\n",
    "        \n",
    "        # 通过最终分类器输出最终结果\n",
    "        final_logits = self.final_classifier(combined_logits)\n",
    "        \n",
    "        # return {\n",
    "        #     'logits': final_logits,  # 最终预测\n",
    "        #     'original_logits': original_logits,  # 原始分类头预测\n",
    "        #     'expert_logits': expert_outputs,  # 各专家预测\n",
    "        #     'routing_weights': routing_weights,  # 路由权重\n",
    "        #     'combined_logits': combined_logits  # 拼接的中间结果\n",
    "        # }\n",
    "        \n",
    "        return final_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "        # 明确指定为word_embeddings\n",
    "        self.emb_name = 'word_embeddings'\n",
    "    \n",
    "    def attack(self, epsilon=1.):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "    \n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 如果在Jupyter Notebook中运行，可以使用这个自定义参数函数替代argparser\n",
    "def get_default_configs():\n",
    "    \"\"\"在Jupyter环境中使用的默认配置，避免argparse解析错误\"\"\"\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            # self.model_name = '/mnt/cfs/huangzhiwei/pykt-moekt/SBM/bge-large-en-v1.5'\n",
    "            # self.model_name = \"/mnt/cfs/huangzhiwei/BAE2025/models/ModernBERT-large\"\n",
    "            # self.model_name = '/mnt/cfs/huangzhiwei/pykt-moekt/SBM/xlm-roberta-large'\n",
    "            # self.model_name = '/mnt/cfs/huangzhiwei/BAE2025/models/bge-base-en-v1.5'\n",
    "            # self.model_name = '/mnt/cfs/huangzhiwei/BAE2025/models/bert-base-uncased'\n",
    "            self.model_name = '/mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base'\n",
    "            # self.model_name = '/mnt/cfs/huangzhiwei/BAE2025/models/roberta-base'\n",
    "            self.num_classes = 3\n",
    "            self.dropout = 0.25\n",
    "            self.freeze_pooler = 8\n",
    "            self.batch_size = 16\n",
    "            self.max_length = 512\n",
    "            self.lr = 2e-5\n",
    "            self.epochs = 50\n",
    "            self.device = device\n",
    "            self.name = None\n",
    "            self.seed = 42\n",
    "            self.data_path = '../data_new/all.json'\n",
    "            self.val_data_path = '../data_new/val.json'\n",
    "            self.checkpoint_dir = '/mnt/cfs/huangzhiwei/BAE2025/projects/predict/5foldx'\n",
    "            self.patience = 6\n",
    "            self.expert_hidden_size = 512\n",
    "            self.num_rnn_layers = 1\n",
    "            self.warmup_ratio = 0.1\n",
    "            self.exp_name = 'BAE2025_track4_bert'\n",
    "\n",
    "            self.cross_validation = True  # 或通过命令行参数设置\n",
    "            self.n_folds = 5  # 或通过命令行参数设置\n",
    "\n",
    "    return Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter environment, using default configs\n",
      "执行5折交叉验证...\n",
      "\n",
      "==================== Fold 1/5 ====================\n",
      "标签分布检查:\n",
      "原始数据集分布: [0.52907916 0.14903069 0.32189015]\n",
      "训练集分布: [0.52929293 0.1489899  0.32171717]\n",
      "验证集分布: [0.52822581 0.14919355 0.32258065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n",
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 0 - Epoch 1/50: 100%|█| 123/123 [00:49<00:00,  2.47batch/s, accuracy=0.500, loss=1.047, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 1.0948\n",
      "Fold 0 - Training Accuracy: 0.3606\n",
      "Fold 0 - Training F1 Score: 0.3155\n",
      "Fold 0 - Validation Loss: 0.9907 Acc: 0.5262 F1: 0.2471\n",
      "Fold 0 - New best model saved with F1: 0.2471, Acc: 0.5262 at Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 2/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.886, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.9958\n",
      "Fold 0 - Training Accuracy: 0.5207\n",
      "Fold 0 - Training F1 Score: 0.2649\n",
      "Fold 0 - Validation Loss: 0.9758 Acc: 0.5363 F1: 0.2518\n",
      "Fold 0 - New best model saved with F1: 0.2518, Acc: 0.5363 at Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 3/50: 100%|█| 123/123 [00:48<00:00,  2.51batch/s, accuracy=0.625, loss=0.862, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.9968\n",
      "Fold 0 - Training Accuracy: 0.5293\n",
      "Fold 0 - Training F1 Score: 0.2868\n",
      "Fold 0 - Validation Loss: 0.9746 Acc: 0.5302 F1: 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 4/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.438, loss=0.998, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.9940\n",
      "Fold 0 - Training Accuracy: 0.5313\n",
      "Fold 0 - Training F1 Score: 0.2958\n",
      "Fold 0 - Validation Loss: 0.9732 Acc: 0.5423 F1: 0.3592\n",
      "Fold 0 - New best model saved with F1: 0.3592, Acc: 0.5423 at Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 5/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.375, loss=1.182, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.9880\n",
      "Fold 0 - Training Accuracy: 0.5303\n",
      "Fold 0 - Training F1 Score: 0.3176\n",
      "Fold 0 - Validation Loss: 0.9733 Acc: 0.5302 F1: 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 6/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.973, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.9607\n",
      "Fold 0 - Training Accuracy: 0.5611\n",
      "Fold 0 - Training F1 Score: 0.3610\n",
      "Fold 0 - Validation Loss: 0.9161 Acc: 0.5847 F1: 0.4202\n",
      "Fold 0 - New best model saved with F1: 0.4202, Acc: 0.5847 at Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 7/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.721, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.9184\n",
      "Fold 0 - Training Accuracy: 0.6071\n",
      "Fold 0 - Training F1 Score: 0.4307\n",
      "Fold 0 - Validation Loss: 0.8855 Acc: 0.6391 F1: 0.4466\n",
      "Fold 0 - New best model saved with F1: 0.4466, Acc: 0.6391 at Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 8/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.720, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.8726\n",
      "Fold 0 - Training Accuracy: 0.6601\n",
      "Fold 0 - Training F1 Score: 0.4809\n",
      "Fold 0 - Validation Loss: 0.8720 Acc: 0.6351 F1: 0.4533\n",
      "Fold 0 - New best model saved with F1: 0.4533, Acc: 0.6351 at Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 9/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.718, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.8542\n",
      "Fold 0 - Training Accuracy: 0.6773\n",
      "Fold 0 - Training F1 Score: 0.4825\n",
      "Fold 0 - Validation Loss: 0.8712 Acc: 0.6230 F1: 0.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 10/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.766, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.8430\n",
      "Fold 0 - Training Accuracy: 0.6894\n",
      "Fold 0 - Training F1 Score: 0.4999\n",
      "Fold 0 - Validation Loss: 0.8416 Acc: 0.6976 F1: 0.4952\n",
      "Fold 0 - New best model saved with F1: 0.4952, Acc: 0.6976 at Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 11/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.844, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.8195\n",
      "Fold 0 - Training Accuracy: 0.6975\n",
      "Fold 0 - Training F1 Score: 0.5049\n",
      "Fold 0 - Validation Loss: 0.8404 Acc: 0.6895 F1: 0.4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 12/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.817, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.7978\n",
      "Fold 0 - Training Accuracy: 0.7217\n",
      "Fold 0 - Training F1 Score: 0.5207\n",
      "Fold 0 - Validation Loss: 0.8545 Acc: 0.6754 F1: 0.4693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 13/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=0.999, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.7964\n",
      "Fold 0 - Training Accuracy: 0.7253\n",
      "Fold 0 - Training F1 Score: 0.5248\n",
      "Fold 0 - Validation Loss: 0.8117 Acc: 0.7097 F1: 0.5047\n",
      "Fold 0 - New best model saved with F1: 0.5047, Acc: 0.7097 at Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 14/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=1.072, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.7667\n",
      "Fold 0 - Training Accuracy: 0.7359\n",
      "Fold 0 - Training F1 Score: 0.5306\n",
      "Fold 0 - Validation Loss: 0.8154 Acc: 0.7036 F1: 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 15/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.703, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.7442\n",
      "Fold 0 - Training Accuracy: 0.7510\n",
      "Fold 0 - Training F1 Score: 0.5485\n",
      "Fold 0 - Validation Loss: 0.8277 Acc: 0.6835 F1: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 16/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.546, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.7344\n",
      "Fold 0 - Training Accuracy: 0.7566\n",
      "Fold 0 - Training F1 Score: 0.5589\n",
      "Fold 0 - Validation Loss: 0.8057 Acc: 0.7036 F1: 0.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 17/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.779, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.7135\n",
      "Fold 0 - Training Accuracy: 0.7672\n",
      "Fold 0 - Training F1 Score: 0.5852\n",
      "Fold 0 - Validation Loss: 0.8084 Acc: 0.7016 F1: 0.5103\n",
      "Fold 0 - New best model saved with F1: 0.5103, Acc: 0.7016 at Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 18/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=0.965, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.6720\n",
      "Fold 0 - Training Accuracy: 0.7955\n",
      "Fold 0 - Training F1 Score: 0.6694\n",
      "Fold 0 - Validation Loss: 0.8118 Acc: 0.6835 F1: 0.5765\n",
      "Fold 0 - New best model saved with F1: 0.5765, Acc: 0.6835 at Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 19/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.943, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.6643\n",
      "Fold 0 - Training Accuracy: 0.8030\n",
      "Fold 0 - Training F1 Score: 0.7025\n",
      "Fold 0 - Validation Loss: 0.8094 Acc: 0.6754 F1: 0.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 20/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.658, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.6602\n",
      "Fold 0 - Training Accuracy: 0.8020\n",
      "Fold 0 - Training F1 Score: 0.7248\n",
      "Fold 0 - Validation Loss: 0.8125 Acc: 0.6754 F1: 0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 21/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.643, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.6222\n",
      "Fold 0 - Training Accuracy: 0.8369\n",
      "Fold 0 - Training F1 Score: 0.7815\n",
      "Fold 0 - Validation Loss: 0.8232 Acc: 0.6552 F1: 0.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 22/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.621, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.6202\n",
      "Fold 0 - Training Accuracy: 0.8338\n",
      "Fold 0 - Training F1 Score: 0.7775\n",
      "Fold 0 - Validation Loss: 0.7983 Acc: 0.6976 F1: 0.6103\n",
      "Fold 0 - New best model saved with F1: 0.6103, Acc: 0.6976 at Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 23/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.483, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5944\n",
      "Fold 0 - Training Accuracy: 0.8540\n",
      "Fold 0 - Training F1 Score: 0.8068\n",
      "Fold 0 - Validation Loss: 0.8180 Acc: 0.6653 F1: 0.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 24/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=1.000, loss=0.316, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5740\n",
      "Fold 0 - Training Accuracy: 0.8662\n",
      "Fold 0 - Training F1 Score: 0.8208\n",
      "Fold 0 - Validation Loss: 0.8256 Acc: 0.6593 F1: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 25/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.696, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5607\n",
      "Fold 0 - Training Accuracy: 0.8768\n",
      "Fold 0 - Training F1 Score: 0.8463\n",
      "Fold 0 - Validation Loss: 0.7933 Acc: 0.6976 F1: 0.6035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 26/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.471, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5718\n",
      "Fold 0 - Training Accuracy: 0.8667\n",
      "Fold 0 - Training F1 Score: 0.8248\n",
      "Fold 0 - Validation Loss: 0.7927 Acc: 0.6875 F1: 0.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 27/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.505, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5402\n",
      "Fold 0 - Training Accuracy: 0.8859\n",
      "Fold 0 - Training F1 Score: 0.8579\n",
      "Fold 0 - Validation Loss: 0.7878 Acc: 0.6915 F1: 0.6174\n",
      "Fold 0 - New best model saved with F1: 0.6174, Acc: 0.6915 at Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 28/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.483, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5359\n",
      "Fold 0 - Training Accuracy: 0.8944\n",
      "Fold 0 - Training F1 Score: 0.8708\n",
      "Fold 0 - Validation Loss: 0.8163 Acc: 0.6673 F1: 0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 29/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.619, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5268\n",
      "Fold 0 - Training Accuracy: 0.8955\n",
      "Fold 0 - Training F1 Score: 0.8756\n",
      "Fold 0 - Validation Loss: 0.8001 Acc: 0.6935 F1: 0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 30/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.584, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5238\n",
      "Fold 0 - Training Accuracy: 0.8990\n",
      "Fold 0 - Training F1 Score: 0.8798\n",
      "Fold 0 - Validation Loss: 0.8058 Acc: 0.6815 F1: 0.5872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 31/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.591, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5211\n",
      "Fold 0 - Training Accuracy: 0.8919\n",
      "Fold 0 - Training F1 Score: 0.8721\n",
      "Fold 0 - Validation Loss: 0.7993 Acc: 0.6895 F1: 0.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 32/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.615, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5096\n",
      "Fold 0 - Training Accuracy: 0.9005\n",
      "Fold 0 - Training F1 Score: 0.8804\n",
      "Fold 0 - Validation Loss: 0.7905 Acc: 0.6875 F1: 0.6074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 - Epoch 33/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.528, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Training Loss: 0.5000\n",
      "Fold 0 - Training Accuracy: 0.9066\n",
      "Fold 0 - Training F1 Score: 0.8923\n",
      "Fold 0 - Validation Loss: 0.8088 Acc: 0.6794 F1: 0.5864\n",
      "Fold 0 - Early stopping triggered after 33 epochs. Best model was at Epoch 27.\n",
      "Fold 1 完成，最佳F1: 0.6174, 最佳准确率: 0.6915\n",
      "\n",
      "==================== Fold 2/5 ====================\n",
      "标签分布检查:\n",
      "原始数据集分布: [0.52907916 0.14903069 0.32189015]\n",
      "训练集分布: [0.52902574 0.14891469 0.32205957]\n",
      "验证集分布: [0.52929293 0.14949495 0.32121212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n",
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 - Epoch 1/50: 100%|█| 123/123 [00:49<00:00,  2.49batch/s, accuracy=0.500, loss=0.955, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 1.1014\n",
      "Fold 1 - Training Accuracy: 0.3776\n",
      "Fold 1 - Training F1 Score: 0.3316\n",
      "Fold 1 - Validation Loss: 0.9907 Acc: 0.5192 F1: 0.2287\n",
      "Fold 1 - New best model saved with F1: 0.2287, Acc: 0.5192 at Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 2/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.500, loss=1.032, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 1.0019\n",
      "Fold 1 - Training Accuracy: 0.5154\n",
      "Fold 1 - Training F1 Score: 0.2782\n",
      "Fold 1 - Validation Loss: 0.9818 Acc: 0.5232 F1: 0.2328\n",
      "Fold 1 - New best model saved with F1: 0.2328, Acc: 0.5232 at Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 3/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.871, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9908\n",
      "Fold 1 - Training Accuracy: 0.5346\n",
      "Fold 1 - Training F1 Score: 0.2951\n",
      "Fold 1 - Validation Loss: 0.9758 Acc: 0.5212 F1: 0.2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 4/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.999, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9873\n",
      "Fold 1 - Training Accuracy: 0.5331\n",
      "Fold 1 - Training F1 Score: 0.3171\n",
      "Fold 1 - Validation Loss: 0.9781 Acc: 0.5253 F1: 0.2334\n",
      "Fold 1 - New best model saved with F1: 0.2334, Acc: 0.5253 at Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 5/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.842, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9861\n",
      "Fold 1 - Training Accuracy: 0.5265\n",
      "Fold 1 - Training F1 Score: 0.2928\n",
      "Fold 1 - Validation Loss: 0.9730 Acc: 0.5475 F1: 0.2955\n",
      "Fold 1 - New best model saved with F1: 0.2955, Acc: 0.5475 at Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 6/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=0.970, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9993\n",
      "Fold 1 - Training Accuracy: 0.5300\n",
      "Fold 1 - Training F1 Score: 0.3161\n",
      "Fold 1 - Validation Loss: 0.9742 Acc: 0.5253 F1: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 7/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.820, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9323\n",
      "Fold 1 - Training Accuracy: 0.6083\n",
      "Fold 1 - Training F1 Score: 0.4174\n",
      "Fold 1 - Validation Loss: 0.8640 Acc: 0.6586 F1: 0.4731\n",
      "Fold 1 - New best model saved with F1: 0.4731, Acc: 0.6586 at Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 8/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.500, loss=1.041, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9273\n",
      "Fold 1 - Training Accuracy: 0.6128\n",
      "Fold 1 - Training F1 Score: 0.4177\n",
      "Fold 1 - Validation Loss: 0.9934 Acc: 0.5253 F1: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 9/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=0.957, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9996\n",
      "Fold 1 - Training Accuracy: 0.5295\n",
      "Fold 1 - Training F1 Score: 0.2557\n",
      "Fold 1 - Validation Loss: 0.9818 Acc: 0.5253 F1: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 10/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.312, loss=1.101, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9967\n",
      "Fold 1 - Training Accuracy: 0.5305\n",
      "Fold 1 - Training F1 Score: 0.2844\n",
      "Fold 1 - Validation Loss: 0.9795 Acc: 0.5253 F1: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 11/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.876, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9890\n",
      "Fold 1 - Training Accuracy: 0.5260\n",
      "Fold 1 - Training F1 Score: 0.2870\n",
      "Fold 1 - Validation Loss: 0.9627 Acc: 0.5253 F1: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 12/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.862, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.9490\n",
      "Fold 1 - Training Accuracy: 0.5861\n",
      "Fold 1 - Training F1 Score: 0.3800\n",
      "Fold 1 - Validation Loss: 0.8414 Acc: 0.7192 F1: 0.5135\n",
      "Fold 1 - New best model saved with F1: 0.5135, Acc: 0.7192 at Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 13/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=1.000, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.8514\n",
      "Fold 1 - Training Accuracy: 0.6648\n",
      "Fold 1 - Training F1 Score: 0.4725\n",
      "Fold 1 - Validation Loss: 0.7946 Acc: 0.7313 F1: 0.5246\n",
      "Fold 1 - New best model saved with F1: 0.5246, Acc: 0.7313 at Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 14/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.500, loss=1.034, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.8319\n",
      "Fold 1 - Training Accuracy: 0.7012\n",
      "Fold 1 - Training F1 Score: 0.5062\n",
      "Fold 1 - Validation Loss: 0.7950 Acc: 0.7293 F1: 0.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 15/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.761, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.8384\n",
      "Fold 1 - Training Accuracy: 0.6921\n",
      "Fold 1 - Training F1 Score: 0.4956\n",
      "Fold 1 - Validation Loss: 0.8062 Acc: 0.7111 F1: 0.5091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 16/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.814, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.8186\n",
      "Fold 1 - Training Accuracy: 0.7092\n",
      "Fold 1 - Training F1 Score: 0.5084\n",
      "Fold 1 - Validation Loss: 0.7785 Acc: 0.7414 F1: 0.5314\n",
      "Fold 1 - New best model saved with F1: 0.5314, Acc: 0.7414 at Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 17/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.692, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7989\n",
      "Fold 1 - Training Accuracy: 0.7224\n",
      "Fold 1 - Training F1 Score: 0.5206\n",
      "Fold 1 - Validation Loss: 0.7740 Acc: 0.7414 F1: 0.5323\n",
      "Fold 1 - New best model saved with F1: 0.5323, Acc: 0.7414 at Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 18/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.907, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7981\n",
      "Fold 1 - Training Accuracy: 0.7092\n",
      "Fold 1 - Training F1 Score: 0.5089\n",
      "Fold 1 - Validation Loss: 0.7665 Acc: 0.7495 F1: 0.5386\n",
      "Fold 1 - New best model saved with F1: 0.5386, Acc: 0.7495 at Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 19/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.934, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7809\n",
      "Fold 1 - Training Accuracy: 0.7345\n",
      "Fold 1 - Training F1 Score: 0.5321\n",
      "Fold 1 - Validation Loss: 0.7812 Acc: 0.7333 F1: 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 20/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.890, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7512\n",
      "Fold 1 - Training Accuracy: 0.7532\n",
      "Fold 1 - Training F1 Score: 0.5457\n",
      "Fold 1 - Validation Loss: 0.7819 Acc: 0.7293 F1: 0.5228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 21/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.768, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7551\n",
      "Fold 1 - Training Accuracy: 0.7501\n",
      "Fold 1 - Training F1 Score: 0.5472\n",
      "Fold 1 - Validation Loss: 0.7723 Acc: 0.7333 F1: 0.5267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 22/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.989, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7415\n",
      "Fold 1 - Training Accuracy: 0.7617\n",
      "Fold 1 - Training F1 Score: 0.5603\n",
      "Fold 1 - Validation Loss: 0.7664 Acc: 0.7394 F1: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 23/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.506, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7368\n",
      "Fold 1 - Training Accuracy: 0.7643\n",
      "Fold 1 - Training F1 Score: 0.5624\n",
      "Fold 1 - Validation Loss: 0.7502 Acc: 0.7455 F1: 0.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Epoch 24/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.534, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Training Loss: 0.7291\n",
      "Fold 1 - Training Accuracy: 0.7557\n",
      "Fold 1 - Training F1 Score: 0.5584\n",
      "Fold 1 - Validation Loss: 0.7719 Acc: 0.7172 F1: 0.5147\n",
      "Fold 1 - Early stopping triggered after 24 epochs. Best model was at Epoch 18.\n",
      "Fold 2 完成，最佳F1: 0.5386, 最佳准确率: 0.7495\n",
      "\n",
      "==================== Fold 3/5 ====================\n",
      "标签分布检查:\n",
      "原始数据集分布: [0.52907916 0.14903069 0.32189015]\n",
      "训练集分布: [0.52902574 0.14891469 0.32205957]\n",
      "验证集分布: [0.52929293 0.14949495 0.32121212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n",
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 - Epoch 1/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=1.013, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 1.0921\n",
      "Fold 2 - Training Accuracy: 0.3720\n",
      "Fold 2 - Training F1 Score: 0.3277\n",
      "Fold 2 - Validation Loss: 0.9930 Acc: 0.5172 F1: 0.2285\n",
      "Fold 2 - New best model saved with F1: 0.2285, Acc: 0.5172 at Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 2/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.949, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.9954\n",
      "Fold 2 - Training Accuracy: 0.5215\n",
      "Fold 2 - Training F1 Score: 0.3123\n",
      "Fold 2 - Validation Loss: 0.9761 Acc: 0.5293 F1: 0.2307\n",
      "Fold 2 - New best model saved with F1: 0.2307, Acc: 0.5293 at Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 3/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=1.005, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.9925\n",
      "Fold 2 - Training Accuracy: 0.5265\n",
      "Fold 2 - Training F1 Score: 0.3002\n",
      "Fold 2 - Validation Loss: 0.9759 Acc: 0.5293 F1: 0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 4/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.438, loss=1.023, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.9890\n",
      "Fold 2 - Training Accuracy: 0.5285\n",
      "Fold 2 - Training F1 Score: 0.3090\n",
      "Fold 2 - Validation Loss: 0.9716 Acc: 0.5293 F1: 0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 5/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.754, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.9914\n",
      "Fold 2 - Training Accuracy: 0.5315\n",
      "Fold 2 - Training F1 Score: 0.3219\n",
      "Fold 2 - Validation Loss: 0.9627 Acc: 0.5596 F1: 0.2957\n",
      "Fold 2 - New best model saved with F1: 0.2957, Acc: 0.5596 at Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 6/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.786, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.9631\n",
      "Fold 2 - Training Accuracy: 0.5628\n",
      "Fold 2 - Training F1 Score: 0.3676\n",
      "Fold 2 - Validation Loss: 0.8820 Acc: 0.6465 F1: 0.4495\n",
      "Fold 2 - New best model saved with F1: 0.4495, Acc: 0.6465 at Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 7/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.500, loss=0.975, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.8912\n",
      "Fold 2 - Training Accuracy: 0.6355\n",
      "Fold 2 - Training F1 Score: 0.4489\n",
      "Fold 2 - Validation Loss: 0.8490 Acc: 0.6848 F1: 0.4806\n",
      "Fold 2 - New best model saved with F1: 0.4806, Acc: 0.6848 at Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 8/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.908, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.8498\n",
      "Fold 2 - Training Accuracy: 0.6774\n",
      "Fold 2 - Training F1 Score: 0.4858\n",
      "Fold 2 - Validation Loss: 0.8077 Acc: 0.7131 F1: 0.5119\n",
      "Fold 2 - New best model saved with F1: 0.5119, Acc: 0.7131 at Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 9/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.759, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.8336\n",
      "Fold 2 - Training Accuracy: 0.6936\n",
      "Fold 2 - Training F1 Score: 0.4967\n",
      "Fold 2 - Validation Loss: 0.8416 Acc: 0.6848 F1: 0.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 10/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.688, loss=0.744, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.8026\n",
      "Fold 2 - Training Accuracy: 0.7092\n",
      "Fold 2 - Training F1 Score: 0.5171\n",
      "Fold 2 - Validation Loss: 0.7976 Acc: 0.7091 F1: 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 11/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.602, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.7648\n",
      "Fold 2 - Training Accuracy: 0.7405\n",
      "Fold 2 - Training F1 Score: 0.5448\n",
      "Fold 2 - Validation Loss: 0.8167 Acc: 0.7071 F1: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 12/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.839, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.7511\n",
      "Fold 2 - Training Accuracy: 0.7532\n",
      "Fold 2 - Training F1 Score: 0.5760\n",
      "Fold 2 - Validation Loss: 0.7738 Acc: 0.7232 F1: 0.5157\n",
      "Fold 2 - New best model saved with F1: 0.5157, Acc: 0.7232 at Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 13/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.777, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.7387\n",
      "Fold 2 - Training Accuracy: 0.7633\n",
      "Fold 2 - Training F1 Score: 0.6049\n",
      "Fold 2 - Validation Loss: 0.8010 Acc: 0.7071 F1: 0.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 14/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.581, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.7348\n",
      "Fold 2 - Training Accuracy: 0.7547\n",
      "Fold 2 - Training F1 Score: 0.6449\n",
      "Fold 2 - Validation Loss: 0.7590 Acc: 0.7455 F1: 0.5351\n",
      "Fold 2 - New best model saved with F1: 0.5351, Acc: 0.7455 at Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 15/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=0.953, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.7069\n",
      "Fold 2 - Training Accuracy: 0.7744\n",
      "Fold 2 - Training F1 Score: 0.6704\n",
      "Fold 2 - Validation Loss: 0.7613 Acc: 0.7232 F1: 0.6071\n",
      "Fold 2 - New best model saved with F1: 0.6071, Acc: 0.7232 at Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 16/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.702, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.6958\n",
      "Fold 2 - Training Accuracy: 0.7910\n",
      "Fold 2 - Training F1 Score: 0.7101\n",
      "Fold 2 - Validation Loss: 0.7684 Acc: 0.7111 F1: 0.6109\n",
      "Fold 2 - New best model saved with F1: 0.6109, Acc: 0.7111 at Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 17/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.572, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.6685\n",
      "Fold 2 - Training Accuracy: 0.8147\n",
      "Fold 2 - Training F1 Score: 0.7438\n",
      "Fold 2 - Validation Loss: 0.7493 Acc: 0.7374 F1: 0.6126\n",
      "Fold 2 - New best model saved with F1: 0.6126, Acc: 0.7374 at Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 18/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.760, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.6436\n",
      "Fold 2 - Training Accuracy: 0.8173\n",
      "Fold 2 - Training F1 Score: 0.7523\n",
      "Fold 2 - Validation Loss: 0.7524 Acc: 0.7374 F1: 0.5968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 19/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.556, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.6514\n",
      "Fold 2 - Training Accuracy: 0.8173\n",
      "Fold 2 - Training F1 Score: 0.7626\n",
      "Fold 2 - Validation Loss: 0.7767 Acc: 0.7071 F1: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 20/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.525, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.6208\n",
      "Fold 2 - Training Accuracy: 0.8284\n",
      "Fold 2 - Training F1 Score: 0.7864\n",
      "Fold 2 - Validation Loss: 0.7543 Acc: 0.7374 F1: 0.6341\n",
      "Fold 2 - New best model saved with F1: 0.6341, Acc: 0.7374 at Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 21/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.541, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.6084\n",
      "Fold 2 - Training Accuracy: 0.8415\n",
      "Fold 2 - Training F1 Score: 0.7973\n",
      "Fold 2 - Validation Loss: 0.7584 Acc: 0.7293 F1: 0.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 22/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=1.106, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.5775\n",
      "Fold 2 - Training Accuracy: 0.8612\n",
      "Fold 2 - Training F1 Score: 0.8281\n",
      "Fold 2 - Validation Loss: 0.7586 Acc: 0.7273 F1: 0.6115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 23/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.534, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.5773\n",
      "Fold 2 - Training Accuracy: 0.8627\n",
      "Fold 2 - Training F1 Score: 0.8325\n",
      "Fold 2 - Validation Loss: 0.7535 Acc: 0.7192 F1: 0.6331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 24/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.554, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.5621\n",
      "Fold 2 - Training Accuracy: 0.8688\n",
      "Fold 2 - Training F1 Score: 0.8389\n",
      "Fold 2 - Validation Loss: 0.7568 Acc: 0.7293 F1: 0.5786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 25/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.632, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.5535\n",
      "Fold 2 - Training Accuracy: 0.8819\n",
      "Fold 2 - Training F1 Score: 0.8582\n",
      "Fold 2 - Validation Loss: 0.7527 Acc: 0.7273 F1: 0.6112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Epoch 26/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.471, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Training Loss: 0.5401\n",
      "Fold 2 - Training Accuracy: 0.8844\n",
      "Fold 2 - Training F1 Score: 0.8630\n",
      "Fold 2 - Validation Loss: 0.7505 Acc: 0.7475 F1: 0.5736\n",
      "Fold 2 - Early stopping triggered after 26 epochs. Best model was at Epoch 20.\n",
      "Fold 3 完成，最佳F1: 0.6341, 最佳准确率: 0.7374\n",
      "\n",
      "==================== Fold 4/5 ====================\n",
      "标签分布检查:\n",
      "原始数据集分布: [0.52907916 0.14903069 0.32189015]\n",
      "训练集分布: [0.52902574 0.14891469 0.32205957]\n",
      "验证集分布: [0.52929293 0.14949495 0.32121212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n",
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 - Epoch 1/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.438, loss=1.082, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 1.0895\n",
      "Fold 3 - Training Accuracy: 0.3796\n",
      "Fold 3 - Training F1 Score: 0.3351\n",
      "Fold 3 - Validation Loss: 0.9927 Acc: 0.5333 F1: 0.2498\n",
      "Fold 3 - New best model saved with F1: 0.2498, Acc: 0.5333 at Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 2/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.889, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.9941\n",
      "Fold 3 - Training Accuracy: 0.5209\n",
      "Fold 3 - Training F1 Score: 0.2919\n",
      "Fold 3 - Validation Loss: 0.9790 Acc: 0.5293 F1: 0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 3/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.750, loss=0.710, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.9948\n",
      "Fold 3 - Training Accuracy: 0.5164\n",
      "Fold 3 - Training F1 Score: 0.3141\n",
      "Fold 3 - Validation Loss: 0.9765 Acc: 0.5212 F1: 0.2882\n",
      "Fold 3 - New best model saved with F1: 0.2882, Acc: 0.5212 at Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 4/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.500, loss=0.957, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.9873\n",
      "Fold 3 - Training Accuracy: 0.5356\n",
      "Fold 3 - Training F1 Score: 0.3403\n",
      "Fold 3 - Validation Loss: 0.9787 Acc: 0.4990 F1: 0.3323\n",
      "Fold 3 - New best model saved with F1: 0.3323, Acc: 0.4990 at Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 5/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.562, loss=1.016, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.9656\n",
      "Fold 3 - Training Accuracy: 0.5462\n",
      "Fold 3 - Training F1 Score: 0.3604\n",
      "Fold 3 - Validation Loss: 0.9624 Acc: 0.5495 F1: 0.2733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 6/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.809, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.8942\n",
      "Fold 3 - Training Accuracy: 0.6421\n",
      "Fold 3 - Training F1 Score: 0.4569\n",
      "Fold 3 - Validation Loss: 0.8985 Acc: 0.6485 F1: 0.4340\n",
      "Fold 3 - New best model saved with F1: 0.4340, Acc: 0.6485 at Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 7/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.653, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.8315\n",
      "Fold 3 - Training Accuracy: 0.6951\n",
      "Fold 3 - Training F1 Score: 0.4973\n",
      "Fold 3 - Validation Loss: 0.8479 Acc: 0.6586 F1: 0.4723\n",
      "Fold 3 - New best model saved with F1: 0.4723, Acc: 0.6586 at Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 8/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.687, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.7916\n",
      "Fold 3 - Training Accuracy: 0.7219\n",
      "Fold 3 - Training F1 Score: 0.5254\n",
      "Fold 3 - Validation Loss: 0.8156 Acc: 0.7091 F1: 0.5048\n",
      "Fold 3 - New best model saved with F1: 0.5048, Acc: 0.7091 at Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 9/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.757, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.7629\n",
      "Fold 3 - Training Accuracy: 0.7420\n",
      "Fold 3 - Training F1 Score: 0.5447\n",
      "Fold 3 - Validation Loss: 0.8221 Acc: 0.7010 F1: 0.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 10/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.438, loss=1.061, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.7682\n",
      "Fold 3 - Training Accuracy: 0.7385\n",
      "Fold 3 - Training F1 Score: 0.5543\n",
      "Fold 3 - Validation Loss: 0.7936 Acc: 0.7131 F1: 0.5076\n",
      "Fold 3 - New best model saved with F1: 0.5076, Acc: 0.7131 at Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 11/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.858, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.7195\n",
      "Fold 3 - Training Accuracy: 0.7597\n",
      "Fold 3 - Training F1 Score: 0.5998\n",
      "Fold 3 - Validation Loss: 0.8066 Acc: 0.7071 F1: 0.5953\n",
      "Fold 3 - New best model saved with F1: 0.5953, Acc: 0.7071 at Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 12/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.623, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.7298\n",
      "Fold 3 - Training Accuracy: 0.7577\n",
      "Fold 3 - Training F1 Score: 0.6506\n",
      "Fold 3 - Validation Loss: 0.7958 Acc: 0.7253 F1: 0.6072\n",
      "Fold 3 - New best model saved with F1: 0.6072, Acc: 0.7253 at Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 13/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.609, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.7027\n",
      "Fold 3 - Training Accuracy: 0.7754\n",
      "Fold 3 - Training F1 Score: 0.6760\n",
      "Fold 3 - Validation Loss: 0.7850 Acc: 0.7333 F1: 0.5986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 14/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.584, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.6951\n",
      "Fold 3 - Training Accuracy: 0.7784\n",
      "Fold 3 - Training F1 Score: 0.6759\n",
      "Fold 3 - Validation Loss: 0.8013 Acc: 0.6929 F1: 0.5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 15/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.713, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.6930\n",
      "Fold 3 - Training Accuracy: 0.7845\n",
      "Fold 3 - Training F1 Score: 0.7107\n",
      "Fold 3 - Validation Loss: 0.7961 Acc: 0.6970 F1: 0.6230\n",
      "Fold 3 - New best model saved with F1: 0.6230, Acc: 0.6970 at Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 16/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.570, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.6448\n",
      "Fold 3 - Training Accuracy: 0.8248\n",
      "Fold 3 - Training F1 Score: 0.7658\n",
      "Fold 3 - Validation Loss: 0.8208 Acc: 0.6768 F1: 0.6010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 17/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.676, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.6575\n",
      "Fold 3 - Training Accuracy: 0.8057\n",
      "Fold 3 - Training F1 Score: 0.7495\n",
      "Fold 3 - Validation Loss: 0.8141 Acc: 0.6929 F1: 0.6084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 18/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.477, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.6186\n",
      "Fold 3 - Training Accuracy: 0.8354\n",
      "Fold 3 - Training F1 Score: 0.7902\n",
      "Fold 3 - Validation Loss: 0.7811 Acc: 0.7131 F1: 0.6232\n",
      "Fold 3 - New best model saved with F1: 0.6232, Acc: 0.7131 at Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 19/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=1.000, loss=0.492, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.6084\n",
      "Fold 3 - Training Accuracy: 0.8460\n",
      "Fold 3 - Training F1 Score: 0.8039\n",
      "Fold 3 - Validation Loss: 0.7887 Acc: 0.7212 F1: 0.5999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 20/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.670, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5977\n",
      "Fold 3 - Training Accuracy: 0.8486\n",
      "Fold 3 - Training F1 Score: 0.8033\n",
      "Fold 3 - Validation Loss: 0.8432 Acc: 0.6586 F1: 0.5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 21/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.617, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5933\n",
      "Fold 3 - Training Accuracy: 0.8516\n",
      "Fold 3 - Training F1 Score: 0.8131\n",
      "Fold 3 - Validation Loss: 0.8096 Acc: 0.6889 F1: 0.6179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 22/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.618, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5904\n",
      "Fold 3 - Training Accuracy: 0.8511\n",
      "Fold 3 - Training F1 Score: 0.8136\n",
      "Fold 3 - Validation Loss: 0.7779 Acc: 0.7111 F1: 0.6306\n",
      "Fold 3 - New best model saved with F1: 0.6306, Acc: 0.7111 at Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 23/50: 100%|█| 123/123 [00:48<00:00,  2.51batch/s, accuracy=0.812, loss=0.637, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5878\n",
      "Fold 3 - Training Accuracy: 0.8455\n",
      "Fold 3 - Training F1 Score: 0.8105\n",
      "Fold 3 - Validation Loss: 0.8081 Acc: 0.6848 F1: 0.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 24/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.750, loss=0.765, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5487\n",
      "Fold 3 - Training Accuracy: 0.8829\n",
      "Fold 3 - Training F1 Score: 0.8490\n",
      "Fold 3 - Validation Loss: 0.7994 Acc: 0.6889 F1: 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 25/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.547, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5463\n",
      "Fold 3 - Training Accuracy: 0.8799\n",
      "Fold 3 - Training F1 Score: 0.8487\n",
      "Fold 3 - Validation Loss: 0.7991 Acc: 0.6949 F1: 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 26/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.812, loss=0.590, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5470\n",
      "Fold 3 - Training Accuracy: 0.8768\n",
      "Fold 3 - Training F1 Score: 0.8440\n",
      "Fold 3 - Validation Loss: 0.8109 Acc: 0.6788 F1: 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 27/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.650, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5238\n",
      "Fold 3 - Training Accuracy: 0.8884\n",
      "Fold 3 - Training F1 Score: 0.8628\n",
      "Fold 3 - Validation Loss: 0.7680 Acc: 0.7253 F1: 0.6188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Epoch 28/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.938, loss=0.589, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Training Loss: 0.5227\n",
      "Fold 3 - Training Accuracy: 0.8925\n",
      "Fold 3 - Training F1 Score: 0.8637\n",
      "Fold 3 - Validation Loss: 0.7781 Acc: 0.7152 F1: 0.6137\n",
      "Fold 3 - Early stopping triggered after 28 epochs. Best model was at Epoch 22.\n",
      "Fold 4 完成，最佳F1: 0.6306, 最佳准确率: 0.7111\n",
      "\n",
      "==================== Fold 5/5 ====================\n",
      "标签分布检查:\n",
      "原始数据集分布: [0.52907916 0.14903069 0.32189015]\n",
      "训练集分布: [0.52902574 0.14941949 0.32155477]\n",
      "验证集分布: [0.52929293 0.14747475 0.32323232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n",
      "当前使用的 tokenizer 类型： <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 - Epoch 1/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.312, loss=1.267, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 1.0769\n",
      "Fold 4 - Training Accuracy: 0.3862\n",
      "Fold 4 - Training F1 Score: 0.3427\n",
      "Fold 4 - Validation Loss: 0.9906 Acc: 0.5192 F1: 0.2369\n",
      "Fold 4 - New best model saved with F1: 0.2369, Acc: 0.5192 at Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 2/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.562, loss=0.954, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 1.0023\n",
      "Fold 4 - Training Accuracy: 0.5164\n",
      "Fold 4 - Training F1 Score: 0.2696\n",
      "Fold 4 - Validation Loss: 0.9726 Acc: 0.5313 F1: 0.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 3/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.438, loss=1.105, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.9865\n",
      "Fold 4 - Training Accuracy: 0.5265\n",
      "Fold 4 - Training F1 Score: 0.2814\n",
      "Fold 4 - Validation Loss: 0.9728 Acc: 0.5313 F1: 0.2352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 4/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.500, loss=1.090, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.9915\n",
      "Fold 4 - Training Accuracy: 0.5300\n",
      "Fold 4 - Training F1 Score: 0.3061\n",
      "Fold 4 - Validation Loss: 0.9694 Acc: 0.5293 F1: 0.2422\n",
      "Fold 4 - New best model saved with F1: 0.2422, Acc: 0.5293 at Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 5/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.688, loss=0.890, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.9811\n",
      "Fold 4 - Training Accuracy: 0.5321\n",
      "Fold 4 - Training F1 Score: 0.3043\n",
      "Fold 4 - Validation Loss: 0.9645 Acc: 0.5253 F1: 0.2444\n",
      "Fold 4 - New best model saved with F1: 0.2444, Acc: 0.5253 at Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 6/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=0.869, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.9650\n",
      "Fold 4 - Training Accuracy: 0.5810\n",
      "Fold 4 - Training F1 Score: 0.3943\n",
      "Fold 4 - Validation Loss: 0.8579 Acc: 0.6949 F1: 0.4932\n",
      "Fold 4 - New best model saved with F1: 0.4932, Acc: 0.6949 at Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 7/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.562, loss=1.036, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.8740\n",
      "Fold 4 - Training Accuracy: 0.6663\n",
      "Fold 4 - Training F1 Score: 0.4710\n",
      "Fold 4 - Validation Loss: 0.8934 Acc: 0.6444 F1: 0.4294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 8/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.625, loss=0.888, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.8716\n",
      "Fold 4 - Training Accuracy: 0.6633\n",
      "Fold 4 - Training F1 Score: 0.4746\n",
      "Fold 4 - Validation Loss: 0.8410 Acc: 0.6828 F1: 0.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 9/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.625, loss=0.911, lr=0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.8396\n",
      "Fold 4 - Training Accuracy: 0.6996\n",
      "Fold 4 - Training F1 Score: 0.5000\n",
      "Fold 4 - Validation Loss: 0.8010 Acc: 0.7232 F1: 0.5135\n",
      "Fold 4 - New best model saved with F1: 0.5135, Acc: 0.7232 at Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 10/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.750, loss=0.680, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.8130\n",
      "Fold 4 - Training Accuracy: 0.7143\n",
      "Fold 4 - Training F1 Score: 0.5146\n",
      "Fold 4 - Validation Loss: 0.7971 Acc: 0.7192 F1: 0.5147\n",
      "Fold 4 - New best model saved with F1: 0.5147, Acc: 0.7192 at Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 11/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.750, loss=0.800, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.8067\n",
      "Fold 4 - Training Accuracy: 0.7183\n",
      "Fold 4 - Training F1 Score: 0.5194\n",
      "Fold 4 - Validation Loss: 0.7878 Acc: 0.7253 F1: 0.5180\n",
      "Fold 4 - New best model saved with F1: 0.5180, Acc: 0.7253 at Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 12/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.688, loss=0.934, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7894\n",
      "Fold 4 - Training Accuracy: 0.7299\n",
      "Fold 4 - Training F1 Score: 0.5315\n",
      "Fold 4 - Validation Loss: 0.7939 Acc: 0.7232 F1: 0.5149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 13/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.875, loss=0.610, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7936\n",
      "Fold 4 - Training Accuracy: 0.7304\n",
      "Fold 4 - Training F1 Score: 0.5309\n",
      "Fold 4 - Validation Loss: 0.7874 Acc: 0.7232 F1: 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 14/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.625, loss=0.991, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7940\n",
      "Fold 4 - Training Accuracy: 0.7269\n",
      "Fold 4 - Training F1 Score: 0.5268\n",
      "Fold 4 - Validation Loss: 0.7937 Acc: 0.7192 F1: 0.5113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 15/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.625, loss=0.977, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7622\n",
      "Fold 4 - Training Accuracy: 0.7481\n",
      "Fold 4 - Training F1 Score: 0.5433\n",
      "Fold 4 - Validation Loss: 0.7773 Acc: 0.7293 F1: 0.5226\n",
      "Fold 4 - New best model saved with F1: 0.5226, Acc: 0.7293 at Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 16/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.875, loss=0.486, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7565\n",
      "Fold 4 - Training Accuracy: 0.7562\n",
      "Fold 4 - Training F1 Score: 0.5491\n",
      "Fold 4 - Validation Loss: 0.7969 Acc: 0.7131 F1: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 17/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.688, loss=0.819, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7490\n",
      "Fold 4 - Training Accuracy: 0.7476\n",
      "Fold 4 - Training F1 Score: 0.5464\n",
      "Fold 4 - Validation Loss: 0.7696 Acc: 0.7354 F1: 0.5274\n",
      "Fold 4 - New best model saved with F1: 0.5274, Acc: 0.7354 at Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 18/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.500, loss=1.016, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7429\n",
      "Fold 4 - Training Accuracy: 0.7607\n",
      "Fold 4 - Training F1 Score: 0.5584\n",
      "Fold 4 - Validation Loss: 0.7956 Acc: 0.7111 F1: 0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 19/50: 100%|█| 123/123 [00:49<00:00,  2.51batch/s, accuracy=0.625, loss=1.028, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7705\n",
      "Fold 4 - Training Accuracy: 0.7436\n",
      "Fold 4 - Training F1 Score: 0.5435\n",
      "Fold 4 - Validation Loss: 0.7991 Acc: 0.7111 F1: 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 20/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.750, loss=0.765, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7561\n",
      "Fold 4 - Training Accuracy: 0.7466\n",
      "Fold 4 - Training F1 Score: 0.5455\n",
      "Fold 4 - Validation Loss: 0.8018 Acc: 0.7030 F1: 0.5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 21/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.688, loss=0.834, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7485\n",
      "Fold 4 - Training Accuracy: 0.7456\n",
      "Fold 4 - Training F1 Score: 0.5412\n",
      "Fold 4 - Validation Loss: 0.7821 Acc: 0.7232 F1: 0.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 22/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.625, loss=0.941, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7481\n",
      "Fold 4 - Training Accuracy: 0.7587\n",
      "Fold 4 - Training F1 Score: 0.5583\n",
      "Fold 4 - Validation Loss: 0.7740 Acc: 0.7313 F1: 0.5236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Epoch 23/50: 100%|█| 123/123 [00:49<00:00,  2.50batch/s, accuracy=0.812, loss=0.641, lr=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Training Loss: 0.7501\n",
      "Fold 4 - Training Accuracy: 0.7481\n",
      "Fold 4 - Training F1 Score: 0.5478\n",
      "Fold 4 - Validation Loss: 0.7707 Acc: 0.7354 F1: 0.5257\n",
      "Fold 4 - Early stopping triggered after 23 epochs. Best model was at Epoch 17.\n",
      "Fold 5 完成，最佳F1: 0.5274, 最佳准确率: 0.7354\n",
      "\n",
      "==================================================\n",
      "交叉验证完成! 5折平均结果:\n",
      "平均最佳F1: 0.5896\n",
      "平均最佳准确率: 0.7250\n",
      "平均最佳Epoch: 20.8\n",
      "各折结果:\n",
      "  Fold 1: F1=0.6174, Acc=0.6915, Best Epoch=27\n",
      "  Fold 2: F1=0.5386, Acc=0.7495, Best Epoch=18\n",
      "  Fold 3: F1=0.6341, Acc=0.7374, Best Epoch=20\n",
      "  Fold 4: F1=0.6306, Acc=0.7111, Best Epoch=22\n",
      "  Fold 5: F1=0.5274, Acc=0.7354, Best Epoch=17\n"
     ]
    }
   ],
   "source": [
    "def train(configs, fold_idx=None):\n",
    "    \n",
    "    # 设置随机种子\n",
    "    random.seed(configs.seed)\n",
    "    np.random.seed(configs.seed)\n",
    "    torch.manual_seed(configs.seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # 创建检查点目录 - 为每个折创建子目录\n",
    "    # if fold_idx is not None:\n",
    "    #     checkpoint_dir = os.path.join(configs.checkpoint_dir, configs.exp_name, f'fold_{fold_idx}')\n",
    "    # else:\n",
    "    #     checkpoint_dir = os.path.join(configs.checkpoint_dir, configs.exp_name)\n",
    "\n",
    "    checkpoint_dir = configs.checkpoint_dir\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # 加载数据集\n",
    "    if fold_idx is None:\n",
    "        # 非交叉验证模式 - 使用原始的训练和验证集\n",
    "        train_dataset = BAE2025Dataset(configs.data_path)\n",
    "        val_dataset = BAE2025Dataset(configs.val_data_path)\n",
    "    else:\n",
    "        # 交叉验证模式 - 使用从全数据集分割的训练集和验证集\n",
    "        # 这些数据集会在cross_validate函数中传入\n",
    "        train_dataset = configs.fold_datasets[fold_idx]['train']\n",
    "        val_dataset = configs.fold_datasets[fold_idx]['val']\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataloader = BAE2025DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=configs.batch_size,\n",
    "        max_length=configs.max_length,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        device=configs.device,\n",
    "        tokenizer_name=configs.model_name\n",
    "    )\n",
    "\n",
    "    val_dataloader = BAE2025DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=configs.batch_size,\n",
    "        max_length=configs.max_length,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        device=configs.device,\n",
    "        tokenizer_name=configs.model_name\n",
    "    )\n",
    "    \n",
    "    # 创建模型\n",
    "    model = DeBERTaMoEClassifier(\n",
    "        pretrained_model_name=configs.model_name,\n",
    "        num_classes=configs.num_classes,\n",
    "        freeze_pooler=configs.freeze_pooler,\n",
    "        num_rnn_layers=configs.num_rnn_layers,\n",
    "        expert_hidden_size=configs.expert_hidden_size,\n",
    "        dropout=configs.dropout\n",
    "    ).to(configs.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 定义优化器\n",
    "    optimizer = AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=configs.lr\n",
    "    )\n",
    "    \n",
    "    # ===== 添加Warmup + Cosine Decay学习率调度 =====\n",
    "    from transformers import get_cosine_schedule_with_warmup\n",
    "    \n",
    "    # 计算总训练步数\n",
    "    total_steps = len(train_dataloader) * configs.epochs\n",
    "    \n",
    "    # 计算warmup步数 (默认总步数的10%，可通过configs.warmup_ratio调整)\n",
    "    warmup_ratio = getattr(configs, 'warmup_ratio', 0.1)  # 如果未定义，则使用默认值0.1\n",
    "    warmup_steps = int(warmup_ratio * total_steps)\n",
    "    \n",
    "    # 创建学习率调度器\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    # ===============================================\n",
    "    \n",
    "    # 初始化最佳验证损失和早停计数器\n",
    "    best_val_acc = 0.0\n",
    "    best_val_f1 = 0.0  # 添加F1分数作为评估指标\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = -1  # 记录达到最佳效果的epoch\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # 定义类别名称\n",
    "    class_names = ['Yes', 'To some extent', 'No']\n",
    "    \n",
    "    # 添加F1计算所需的库\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    # 获得对应embedding名字\n",
    "    # 打印模型中的层名称，查找嵌入层\n",
    "    # for name, _ in model.named_parameters():\n",
    "    #     if 'embed' in name:\n",
    "    #         print(name)\n",
    "    \n",
    "    # # 设置FGM的嵌入层名称\n",
    "    # fgm = FGM(model)\n",
    "    # fgm.emb_name = 'word_embeddings'  # 根据打印结果调整正确的名称\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(configs.epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        train_preds = []\n",
    "        train_labels_list = []\n",
    "        \n",
    "        with tqdm(\n",
    "            train_dataloader,\n",
    "            total=len(train_dataloader),\n",
    "            desc=f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - Epoch {epoch + 1}/{configs.epochs}',\n",
    "            unit='batch',\n",
    "            ncols=100\n",
    "        ) as pbar:\n",
    "            for input_ids, attention_mask, labels in pbar:\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 前向传播\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                \n",
    "                # 计算损失 - 确保labels是长整型\n",
    "                labels = labels.long()\n",
    "                loss = criterion(logits, labels)\n",
    "                # 反向传播\n",
    "                loss.backward()\n",
    "\n",
    "                # # FGM对抗训练\n",
    "                # fgm.attack()  # 在嵌入层添加扰动\n",
    "                # # 对抗样本的前向传播\n",
    "                # logits_adv = model(input_ids, attention_mask)\n",
    "                # # 计算对抗损失\n",
    "                # loss_adv = criterion(logits_adv, labels)\n",
    "                # # 反向传播\n",
    "                # loss_adv.backward()\n",
    "                # # 恢复嵌入层参数\n",
    "                # fgm.restore()\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()  # 更新学习率\n",
    "                \n",
    "                preds = logits.argmax(dim=1)\n",
    "                accuracy = (preds == labels).float().mean()\n",
    "                accuracy_all = (preds == labels).float().sum()\n",
    "                \n",
    "                # 收集预测结果和真实标签，用于计算F1\n",
    "                train_preds.extend(preds.cpu().numpy())\n",
    "                train_labels_list.extend(labels.cpu().numpy())\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_acc += accuracy_all.item()\n",
    "                \n",
    "                # 添加当前学习率到进度条\n",
    "                curr_lr = scheduler.get_last_lr()[0]\n",
    "                pbar.set_postfix(\n",
    "                    loss=f'{loss.item():.3f}',\n",
    "                    accuracy=f'{accuracy.item():.3f}',\n",
    "                    lr=f'{curr_lr:.6f}'  # 显示当前学习率\n",
    "                )\n",
    "        \n",
    "        train_loss = train_loss / len(train_dataloader)\n",
    "        train_acc = train_acc / len(train_dataset)\n",
    "        \n",
    "        # 计算训练集的F1分数 - 使用macro平均以处理多分类\n",
    "        train_f1 = f1_score(train_labels_list, train_preds, average='macro')\n",
    "        \n",
    "        print(f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - Training Loss: {train_loss:.4f}')\n",
    "        print(f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - Training Accuracy: {train_acc:.4f}')\n",
    "        print(f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - Training F1 Score: {train_f1:.4f}')\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0.0\n",
    "        val_preds = []\n",
    "        val_labels_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for input_ids, attention_mask, labels in val_dataloader:\n",
    "                # 确保labels是长整型\n",
    "                labels = labels.long()\n",
    "                \n",
    "                # 前向传播\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                \n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = logits.argmax(dim=1)\n",
    "                accuracy = (preds == labels).float().sum()\n",
    "                val_corrects += accuracy\n",
    "                \n",
    "                # 收集预测结果和真实标签，用于计算F1\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels_list.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_loss / len(val_dataloader)\n",
    "        val_acc = val_corrects.double() / len(val_dataset)\n",
    "        \n",
    "        # 计算验证集的F1分数\n",
    "        val_f1 = f1_score(val_labels_list, val_preds, average='macro')\n",
    "        \n",
    "        print(f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}')\n",
    "        \n",
    "        # 检查是否保存模型并判断是否需要早停\n",
    "        # 使用F1分数作为主要指标\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1  # 记录达到最佳效果的epoch\n",
    "            \n",
    "            # 保存模型 - 为每个折添加fold_idx到文件名\n",
    "            if fold_idx is not None:\n",
    "                model_path = os.path.join(checkpoint_dir, f'best_model_fold_{fold_idx}.pt')\n",
    "            else:\n",
    "                model_path = os.path.join(checkpoint_dir, 'best_model_f1.pt')\n",
    "            \n",
    "            state_dict = model.state_dict()\n",
    "            torch.save(state_dict, model_path)\n",
    "            print(f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - New best model saved with F1: {best_val_f1:.4f}, Acc: {best_val_acc:.4f} at Epoch {best_epoch}')\n",
    "            \n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= configs.patience:\n",
    "                print(f'Fold {fold_idx if fold_idx is not None else \"N/A\"} - Early stopping triggered after {epoch+1} epochs. Best model was at Epoch {best_epoch}.')\n",
    "                break\n",
    "    \n",
    "    # 返回最佳验证指标，用于交叉验证结果汇总\n",
    "    return {\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'best_epoch': best_epoch\n",
    "    }\n",
    "\n",
    "\n",
    "def cross_validate(configs, n_folds=5):\n",
    "    \"\"\"\n",
    "    执行n折交叉验证\n",
    "    \n",
    "    参数:\n",
    "    - configs: 配置对象\n",
    "    - n_folds: 交叉验证的折数，默认为5\n",
    "    \"\"\"\n",
    "    # 导入所需库\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    import numpy as np\n",
    "    \n",
    "    # 首先加载完整的数据集\n",
    "    full_dataset = BAE2025Dataset(configs.data_path)\n",
    "    \n",
    "    # 获取标签，用于分层抽样 - 修改这一行\n",
    "    labels = [data[1] for data in full_dataset.data]  # 使用.data而不是.samples\n",
    "    \n",
    "    # 创建分层K折交叉验证对象\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=configs.seed)\n",
    "    \n",
    "    # 存储每个折的数据集\n",
    "    configs.fold_datasets = []\n",
    "    \n",
    "    # 存储每个折的结果\n",
    "    fold_results = []\n",
    "    \n",
    "    # 遍历每个折\n",
    "    for fold_idx, (train_indices, val_indices) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "        print(f\"\\n{'='*20} Fold {fold_idx+1}/{n_folds} {'='*20}\")\n",
    "        \n",
    "        # 为当前折创建训练集和验证集 - 修改这些行\n",
    "        train_samples = [full_dataset.data[i] for i in train_indices]\n",
    "        val_samples = [full_dataset.data[i] for i in val_indices]\n",
    "        \n",
    "        # 创建新的数据集对象\n",
    "        train_dataset = BAE2025Dataset(None)  # 创建空数据集\n",
    "        train_dataset.data = train_samples  # 填充训练样本，使用.data而不是.samples\n",
    "        \n",
    "        val_dataset = BAE2025Dataset(None)  # 创建空数据集\n",
    "        val_dataset.data = val_samples  # 填充验证样本，使用.data而不是.samples\n",
    "        \n",
    "        # 保存当前折的数据集\n",
    "        configs.fold_datasets.append({\n",
    "            'train': train_dataset,\n",
    "            'val': val_dataset\n",
    "        })\n",
    "        \n",
    "        # 检查标签分布是否保持一致 - 修改这些行\n",
    "        train_label_dist = np.bincount(np.array([s[1] for s in train_samples])) / len(train_samples)\n",
    "        val_label_dist = np.bincount(np.array([s[1] for s in val_samples])) / len(val_samples)\n",
    "        full_label_dist = np.bincount(np.array(labels)) / len(labels)\n",
    "        \n",
    "        print(f\"标签分布检查:\")\n",
    "        print(f\"原始数据集分布: {full_label_dist}\")\n",
    "        print(f\"训练集分布: {train_label_dist}\")\n",
    "        print(f\"验证集分布: {val_label_dist}\")\n",
    "        \n",
    "        # 训练当前折\n",
    "        fold_result = train(configs, fold_idx=fold_idx)\n",
    "        fold_results.append(fold_result)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1} 完成，最佳F1: {fold_result['best_val_f1']:.4f}, 最佳准确率: {fold_result['best_val_acc']:.4f}\")\n",
    "    \n",
    "    # 计算交叉验证的平均结果\n",
    "    avg_f1 = sum(r['best_val_f1'] for r in fold_results) / n_folds\n",
    "    avg_acc = sum(r['best_val_acc'] for r in fold_results) / n_folds\n",
    "    avg_epoch = sum(r['best_epoch'] for r in fold_results) / n_folds\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"交叉验证完成! {n_folds}折平均结果:\")\n",
    "    print(f\"平均最佳F1: {avg_f1:.4f}\")\n",
    "    print(f\"平均最佳准确率: {avg_acc:.4f}\")\n",
    "    print(f\"平均最佳Epoch: {avg_epoch:.1f}\")\n",
    "    print(\"各折结果:\")\n",
    "    for fold_idx, result in enumerate(fold_results):\n",
    "        print(f\"  Fold {fold_idx+1}: F1={result['best_val_f1']:.4f}, Acc={result['best_val_acc']:.4f}, Best Epoch={result['best_epoch']}\")\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "\n",
    "# 在以下主函数中添加判断Jupyter环境的逻辑\n",
    "if __name__ == '__main__':\n",
    "    # 判断是否在Jupyter环境中运行\n",
    "    try:\n",
    "        # 检查是否在Jupyter中运行\n",
    "        get_ipython = globals().get('get_ipython', None)\n",
    "        if get_ipython and 'IPKernelApp' in get_ipython().config:\n",
    "            # 在Jupyter环境中运行，使用默认配置\n",
    "            print(\"Running in Jupyter environment, using default configs\")\n",
    "            configs = get_default_configs()\n",
    "        else:\n",
    "            # 在命令行环境中运行，使用argparse\n",
    "            configs = argparser()\n",
    "    except:\n",
    "        # 任何异常都使用argparse处理\n",
    "        configs = argparser()\n",
    "    \n",
    "    # 设置实验名称\n",
    "    if configs.name is None:\n",
    "        configs.exp_name = \\\n",
    "            f'{os.path.basename(configs.model_name)}' + \\\n",
    "            f'{\"_fp\" if configs.freeze_pooler else \"\"}' + \\\n",
    "            f'_b{configs.batch_size}_e{configs.epochs}' + \\\n",
    "            f'_len{configs.max_length}_lr{configs.lr}'\n",
    "    else:\n",
    "        configs.exp_name = configs.name\n",
    "    \n",
    "    # 设置设备\n",
    "    if configs.device is None:\n",
    "        configs.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "    \n",
    "    # 判断是否使用交叉验证\n",
    "    use_cv = getattr(configs, 'cross_validation', False)\n",
    "    n_folds = getattr(configs, 'n_folds', 5)\n",
    "    \n",
    "    if use_cv:\n",
    "        # 执行交叉验证\n",
    "        print(f\"执行{n_folds}折交叉验证...\")\n",
    "        cross_validate(configs, n_folds=n_folds)\n",
    "    else:\n",
    "        # 执行常规训练\n",
    "        print(\"执行常规训练...\")\n",
    "        train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
