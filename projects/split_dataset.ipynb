{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 长度为300的列表，切分训练集和验证集，0.8为训练集，0.2为验证集，json文件格式，同时切成json文件保存\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "    \n",
    "# 切分训练集和验证集\n",
    "train_data = datas[:int(len(datas)*0.8)]\n",
    "valid_data = datas[int(len(datas)*0.8):]\n",
    "\n",
    "# 保存训练集和验证集\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(valid_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - 训练集大小: 240, 验证集大小: 60\n",
      "Fold 0 - 训练集前5个索引: [0 1 2 3 4]\n",
      "Fold 0 - 验证集前5个索引: [ 5  7  9 17 24]\n",
      "Fold 1 - 训练集大小: 240, 验证集大小: 60\n",
      "Fold 1 - 训练集前5个索引: [0 1 2 3 4]\n",
      "Fold 1 - 验证集前5个索引: [ 6 10 15 16 18]\n",
      "Fold 2 - 训练集大小: 240, 验证集大小: 60\n",
      "Fold 2 - 训练集前5个索引: [0 1 3 4 5]\n",
      "Fold 2 - 验证集前5个索引: [ 2 12 26 28 29]\n",
      "Fold 3 - 训练集大小: 240, 验证集大小: 60\n",
      "Fold 3 - 训练集前5个索引: [1 2 3 5 6]\n",
      "Fold 3 - 验证集前5个索引: [ 0  4  8 11 14]\n",
      "Fold 4 - 训练集大小: 240, 验证集大小: 60\n",
      "Fold 4 - 训练集前5个索引: [0 2 4 5 6]\n",
      "Fold 4 - 验证集前5个索引: [ 1  3 13 20 21]\n",
      "所有5折交叉验证数据已保存完成!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 读取数据\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "    \n",
    "# 创建5折交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 获取所有折的索引并保存\n",
    "all_folds = []\n",
    "for train_index, valid_index in kf.split(datas):\n",
    "    all_folds.append({\n",
    "        \"train_indices\": train_index.tolist(),\n",
    "        \"valid_indices\": valid_index.tolist()\n",
    "    })\n",
    "\n",
    "# 保存所有折的索引信息\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/fold_indices.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_folds, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 原有的代码继续执行...\n",
    "fold = 0\n",
    "for train_index, valid_index in kf.split(datas):\n",
    "    # 根据索引获取对应的数据\n",
    "    train_data = [datas[i] for i in train_index]\n",
    "    valid_data = [datas[i] for i in valid_index]\n",
    "    \n",
    "    # 保存当前折的训练集和验证集\n",
    "    with open(f'/mnt/cfs/huangzhiwei/BAE2025/data/train_fold{fold}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    with open(f'/mnt/cfs/huangzhiwei/BAE2025/data/valid_fold{fold}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f'Fold {fold} - 训练集大小: {len(train_data)}, 验证集大小: {len(valid_data)}')\n",
    "    \n",
    "    # 打印前几个索引，帮助调试\n",
    "    print(f\"Fold {fold} - 训练集前5个索引: {train_index[:5]}\")\n",
    "    print(f\"Fold {fold} - 验证集前5个索引: {valid_index[:5]}\")\n",
    "    fold += 1\n",
    "\n",
    "print('所有5折交叉验证数据已保存完成!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 240 对话, 验证集大小: 60 对话\n",
      "训练集占比: 0.80\n",
      "\n",
      "标签分布:\n",
      "训练集 (1975 样本):\n",
      "  - Yes: 1107 (56.05%)\n",
      "  - To some extent: 417 (21.11%)\n",
      "  - No: 451 (22.84%)\n",
      "验证集 (501 样本):\n",
      "  - Yes: 300 (59.88%)\n",
      "  - To some extent: 86 (17.17%)\n",
      "  - No: 115 (22.95%)\n",
      "\n",
      "数据已保存!\n"
     ]
    }
   ],
   "source": [
    "# 新的数据划分方法，基于conversation_id划分\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "# 提取所有唯一的conversation_id\n",
    "conversation_ids = list(set(data[\"conversation_id\"] for data in datas))\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 按照0.8:0.2的比例划分conversation_ids\n",
    "train_conversation_ids, valid_conversation_ids = train_test_split(\n",
    "    conversation_ids, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 根据对话ID筛选数据\n",
    "train_data = [data for data in datas if data[\"conversation_id\"] in train_conversation_ids]\n",
    "valid_data = [data for data in datas if data[\"conversation_id\"] in valid_conversation_ids]\n",
    "\n",
    "# 打印划分信息\n",
    "print(f'训练集大小: {len(train_data)} 对话, 验证集大小: {len(valid_data)} 对话')\n",
    "print(f'训练集占比: {len(train_data) / (len(train_data) + len(valid_data)):.2f}')\n",
    "\n",
    "# 检查类别分布\n",
    "def count_labels(data_list):\n",
    "    label_counts = {\"Yes\": 0, \"To some extent\": 0, \"No\": 0}\n",
    "    total_samples = 0\n",
    "    \n",
    "    for data in data_list:\n",
    "        for model, response_data in data[\"tutor_responses\"].items():\n",
    "            label = response_data[\"annotation\"][\"Providing_Guidance\"]\n",
    "            label_counts[label] += 1\n",
    "            total_samples += 1\n",
    "    \n",
    "    return label_counts, total_samples\n",
    "\n",
    "train_labels, train_samples = count_labels(train_data)\n",
    "valid_labels, valid_samples = count_labels(valid_data)\n",
    "\n",
    "print(\"\\n标签分布:\")\n",
    "print(f\"训练集 ({train_samples} 样本):\")\n",
    "for label, count in train_labels.items():\n",
    "    print(f\"  - {label}: {count} ({count/train_samples*100:.2f}%)\")\n",
    "\n",
    "print(f\"验证集 ({valid_samples} 样本):\")\n",
    "for label, count in valid_labels.items():\n",
    "    print(f\"  - {label}: {count} ({count/valid_samples*100:.2f}%)\")\n",
    "\n",
    "# 保存划分后的数据\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(valid_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print('\\n数据已保存!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中conversation_history长度超过512的数量: 185\n",
      "验证集中conversation_history长度超过512的数量: 39\n"
     ]
    }
   ],
   "source": [
    "# 检测一下train.json和valid.json的数据中“conversation_history”长度超过512的数量\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/valid.json', 'r', encoding='utf-8') as f:\n",
    "    valid_data = json.load(f)\n",
    "\n",
    "train_count = 0\n",
    "valid_count = 0\n",
    "\n",
    "for data in train_data:\n",
    "    if len(data[\"conversation_history\"]) > 512:\n",
    "        train_count += 1\n",
    "\n",
    "for data in valid_data:\n",
    "    if len(data[\"conversation_history\"]) > 512:\n",
    "        valid_count += 1\n",
    "\n",
    "print(f'训练集中conversation_history长度超过512的数量: {train_count}')\n",
    "print(f'验证集中conversation_history长度超过512的数量: {valid_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切分新的训练集和测试集（1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 444 对话, 验证集大小: 112 对话\n",
      "训练集占比: 0.80\n",
      "\n",
      "标签分布:\n",
      "训练集 (2205 样本):\n",
      "  - Yes: 1171 (53.11%)\n",
      "  - To some extent: 514 (23.31%)\n",
      "  - No: 520 (23.58%)\n",
      "验证集 (527 样本):\n",
      "  - Yes: 272 (51.61%)\n",
      "  - To some extent: 125 (23.72%)\n",
      "  - No: 130 (24.67%)\n",
      "\n",
      "数据已保存!\n"
     ]
    }
   ],
   "source": [
    "# 新的数据划分方法，基于conversation_id划分\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/extend_1_8+8.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "# 提取所有唯一的conversation_id\n",
    "conversation_ids = list(set(data[\"conversation_id\"] for data in datas))\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 按照0.8:0.2的比例划分conversation_ids\n",
    "train_conversation_ids, valid_conversation_ids = train_test_split(\n",
    "    conversation_ids, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 根据对话ID筛选数据\n",
    "train_data = [data for data in datas if data[\"conversation_id\"] in train_conversation_ids]\n",
    "valid_data = [data for data in datas if data[\"conversation_id\"] in valid_conversation_ids]\n",
    "\n",
    "# 打印划分信息\n",
    "print(f'训练集大小: {len(train_data)} 对话, 验证集大小: {len(valid_data)} 对话')\n",
    "print(f'训练集占比: {len(train_data) / (len(train_data) + len(valid_data)):.2f}')\n",
    "\n",
    "# 检查类别分布\n",
    "def count_labels(data_list):\n",
    "    label_counts = {\"Yes\": 0, \"To some extent\": 0, \"No\": 0}\n",
    "    total_samples = 0\n",
    "    \n",
    "    for data in data_list:\n",
    "        for model, response_data in data[\"tutor_responses\"].items():\n",
    "            label = response_data[\"annotation\"][\"Providing_Guidance\"]\n",
    "            label_counts[label] += 1\n",
    "            total_samples += 1\n",
    "    \n",
    "    return label_counts, total_samples\n",
    "\n",
    "train_labels, train_samples = count_labels(train_data)\n",
    "valid_labels, valid_samples = count_labels(valid_data)\n",
    "\n",
    "print(\"\\n标签分布:\")\n",
    "print(f\"训练集 ({train_samples} 样本):\")\n",
    "for label, count in train_labels.items():\n",
    "    print(f\"  - {label}: {count} ({count/train_samples*100:.2f}%)\")\n",
    "\n",
    "print(f\"验证集 ({valid_samples} 样本):\")\n",
    "for label, count in valid_labels.items():\n",
    "    print(f\"  - {label}: {count} ({count/valid_samples*100:.2f}%)\")\n",
    "\n",
    "# 保存划分后的数据\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/train_8+8.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/valid_8+8.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(valid_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print('\\n数据已保存!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测一下train.json和valid.json的数据中“conversation_history”长度超过512的数量\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data_extend/valid.json', 'r', encoding='utf-8') as f:\n",
    "    valid_data = json.load(f)\n",
    "\n",
    "train_count = 0\n",
    "valid_count = 0\n",
    "\n",
    "for data in train_data:\n",
    "    if len(data[\"conversation_history\"]) > 512:\n",
    "        train_count += 1\n",
    "\n",
    "for data in valid_data:\n",
    "    if len(data[\"conversation_history\"]) > 512:\n",
    "        valid_count += 1\n",
    "\n",
    "print(f'训练集中conversation_history长度超过512的数量: {train_count}')\n",
    "print(f'验证集中conversation_history长度超过512的数量: {valid_count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
