{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查一下数据里的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistake Identification Counts: {'To some extent': 174, 'No': 370, 'Yes': 1932}\n",
      "Mistake Location Counts: {'To some extent': 220, 'No': 713, 'Yes': 1543}\n",
      "Providing Guidance Counts: {'To some extent': 503, 'No': 566, 'Yes': 1407}\n",
      "Actionability Counts: {'To some extent': 369, 'No': 797, 'Yes': 1310}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 打开json文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "annotations = []\n",
    "for data in datas:\n",
    "    tutor_responses = data['tutor_responses']\n",
    "    for tutor_response in tutor_responses.values():  # Use .values() to access the response dict  用.values()访问响应字典\n",
    "        annotation = tutor_response['annotation']  # Safely access 'annotation'\n",
    "        if isinstance(annotation, dict):  # Check if 'annotation' is a dictionary\n",
    "            annotations.append(annotation)\n",
    "\n",
    "# Collect the values for each category\n",
    "Mistake_Identification = [annotation['Mistake_Identification'] for annotation in annotations]\n",
    "Mistake_Location = [annotation['Mistake_Location'] for annotation in annotations]\n",
    "Providing_Guidance = [annotation['Providing_Guidance'] for annotation in annotations]\n",
    "Actionability = [annotation['Actionability'] for annotation in annotations]\n",
    "\n",
    "# Count occurrences of each value\n",
    "mistake_identification_counts = {value: Mistake_Identification.count(value) for value in set(Mistake_Identification)}\n",
    "mistake_location_counts = {value: Mistake_Location.count(value) for value in set(Mistake_Location)}\n",
    "providing_guidance_counts = {value: Providing_Guidance.count(value) for value in set(Providing_Guidance)}\n",
    "actionability_counts = {value: Actionability.count(value) for value in set(Actionability)}\n",
    "\n",
    "# 输出看一下详细情况\n",
    "print(\"Mistake Identification Counts:\", mistake_identification_counts)\n",
    "print(\"Mistake Location Counts:\", mistake_location_counts)\n",
    "print(\"Providing Guidance Counts:\", providing_guidance_counts)\n",
    "print(\"Actionability Counts:\", actionability_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查一下是否有缺失值或者乱码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chardet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m  \u001b[38;5;66;03m# 用于字符编码检测\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_missing_values\u001b[39m(data):\n\u001b[1;32m      5\u001b[0m     missing_values \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chardet'"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import chardet  # 用于字符编码检测\n",
    "\n",
    "# def check_missing_values(data):\n",
    "#     missing_values = {}\n",
    "#     for idx, item in enumerate(data):\n",
    "#         for key, value in item.items():\n",
    "#             if value is None or (isinstance(value, str) and value.strip() == \"\"):\n",
    "#                 if key not in missing_values:\n",
    "#                     missing_values[key] = []\n",
    "#                 missing_values[key].append((idx, value))  # 存储缺失值所在的索引\n",
    "#     return missing_values\n",
    "\n",
    "# def check_encoding(data):\n",
    "#     encoding_issues = []\n",
    "#     for idx, item in enumerate(data):\n",
    "#         for key, value in item.items():\n",
    "#             if isinstance(value, str):\n",
    "#                 # 检测字符串的编码\n",
    "#                 result = chardet.detect(value.encode())\n",
    "#                 if result['encoding'] != 'utf-8':  # 你可以根据需要检查其它编码\n",
    "#                     encoding_issues.append((idx, key, value, result['encoding']))\n",
    "#     return encoding_issues\n",
    "\n",
    "# # 读取JSON文件\n",
    "# with open('/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json', 'r', encoding='utf-8') as f:\n",
    "#     datas = json.load(f)\n",
    "\n",
    "# # 检查缺失值\n",
    "# missing_values = check_missing_values(datas)\n",
    "# if missing_values:\n",
    "#     print(\"Missing Values Detected:\")\n",
    "#     for key, issues in missing_values.items():\n",
    "#         print(f\"{key} has missing values at indices: {issues}\")\n",
    "# else:\n",
    "#     print(\"No missing values detected.\")\n",
    "\n",
    "# # 检查编码问题\n",
    "# encoding_issues = check_encoding(datas)\n",
    "# if encoding_issues:\n",
    "#     print(\"\\nEncoding Issues Detected:\")\n",
    "#     for issue in encoding_issues:\n",
    "#         print(f\"At index {issue[0]}, key '{issue[1]}' has encoding issues. Original value: '{issue[2]}', Detected encoding: {issue[3]}\")\n",
    "# else:\n",
    "#     print(\"No encoding issues detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查一下句子的最大长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of conversation history: 2021\n",
      "Number of conversation history with length <= 128: 35\n",
      "Number of conversation history with length <= 256: 41\n",
      "Number of conversation history with length <= 512: 0\n",
      "Number of conversation history with length <= 1024: 35\n",
      "Number of conversation history with length > 1024: 189\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 打开json文件\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "annotations = []\n",
    "max_length = 0\n",
    "cnt = 0\n",
    "cnt_128 = 0\n",
    "cnt_256 = 0\n",
    "cnt_512 = 0\n",
    "cnt_1024 = 0\n",
    "for data in datas:\n",
    "    tutor_responses = data['conversation_history']\n",
    "    if len(tutor_responses) > max_length:\n",
    "        max_length = len(tutor_responses)\n",
    "    if len(tutor_responses) > 1024:\n",
    "        cnt_1024 += 1\n",
    "    elif len(tutor_responses) > 512:\n",
    "        cnt_512 += 1\n",
    "    elif len(tutor_responses) > 256:\n",
    "        cnt_256 += 1\n",
    "    elif len(tutor_responses) > 128:\n",
    "        cnt_128 += 1\n",
    "    else:\n",
    "        cnt += 1\n",
    "\n",
    "print(\"Max length of conversation history:\", max_length)\n",
    "\n",
    "# 输出看一下句子长度情况\n",
    "print(\"Number of conversation history with length <= 128:\", cnt)\n",
    "print(\"Number of conversation history with length <= 256:\", cnt_128)\n",
    "print(\"Number of conversation history with length <= 512:\", cnt_256)\n",
    "print(\"Number of conversation history with length <= 1024:\", cnt_512)\n",
    "print(\"Number of conversation history with length > 1024:\", cnt_1024)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1547\n",
      "yes: 841      yes: 0.5436328377504848\n",
      "to some extent: 317      to some extent: 0.20491273432449902\n",
      "no: 389\n",
      "no: 0.25145442792501616\n"
     ]
    }
   ],
   "source": [
    "with open('/mnt/cfs/huangzhiwei/BAE2025/projects/predict/predictions_x.json', 'r', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "\n",
    "\n",
    "yes = 0\n",
    "to_some_extent = 0\n",
    "no = 0\n",
    "total = 0\n",
    "\n",
    "for data in datas:\n",
    "    tutror_responses = data['tutor_responses']\n",
    "    for tutor_response in tutror_responses.values():\n",
    "        if tutor_response['annotation'][\"Actionability\"] == 'Yes':\n",
    "            yes += 1\n",
    "        elif tutor_response['annotation'][\"Actionability\"] == 'To some extent':\n",
    "            to_some_extent += 1\n",
    "        elif tutor_response['annotation'][\"Actionability\"] == 'No':\n",
    "            no += 1\n",
    "        total += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"yes:\", yes, end=\"      \")\n",
    "print(\"yes:\", yes / total)\n",
    "print(\"to some extent:\", to_some_extent, end=\"      \")\n",
    "print(\"to some extent:\", to_some_extent / total)\n",
    "print(\"no:\", no)\n",
    "print(\"no:\", no / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
