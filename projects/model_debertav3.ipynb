{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json\n",
      "Successfully loaded JSON data with 300 entries\n",
      "Total samples: 2476\n",
      "Label distribution: {2: 1310, 0: 797, 1: 369}\n",
      "Starting cross-validation with the following parameters:\n",
      "  data_file: /mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json\n",
      "  model_name: /mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base\n",
      "  max_length: 512\n",
      "  dropout: 0.2\n",
      "  learning_rate: 2e-05\n",
      "  batch_size: 16\n",
      "  epochs: 40\n",
      "  warmup_steps: 0\n",
      "  weight_decay: 0.01\n",
      "  gradient_clip: 1.0\n",
      "  early_stopping: True\n",
      "  patience: 6\n",
      "  min_delta: 0.001\n",
      "  metric_for_early_stopping: macro_f1\n",
      "  n_splits: 5\n",
      "  random_state: 42\n",
      "  save_model: False\n",
      "  model_path: /mnt/cfs/huangzhiwei/BAE2025/projects/checkpoints_debertav3/best_model.pt\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.85it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9623\n",
      "Training accuracy: 0.5359\n",
      "Training weighted F1 score: 0.4214\n",
      "Training macro F1 score: 0.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.71it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6794\n",
      "Validation weighted F1 score: 0.6247\n",
      "Validation macro F1 score: 0.4831\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.74      0.66      0.70       176\n",
      "To some extent       0.00      0.00      0.00        71\n",
      "           Yes       0.65      0.89      0.75       249\n",
      "\n",
      "      accuracy                           0.68       496\n",
      "     macro avg       0.46      0.52      0.48       496\n",
      "  weighted avg       0.59      0.68      0.62       496\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7622\n",
      "Training accuracy: 0.7091\n",
      "Training weighted F1 score: 0.6501\n",
      "Training macro F1 score: 0.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.76it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6331\n",
      "Validation weighted F1 score: 0.5852\n",
      "Validation macro F1 score: 0.4548\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.53      0.95      0.68       176\n",
      "To some extent       0.00      0.00      0.00        71\n",
      "           Yes       0.82      0.59      0.69       249\n",
      "\n",
      "      accuracy                           0.63       496\n",
      "     macro avg       0.45      0.51      0.45       496\n",
      "  weighted avg       0.60      0.63      0.59       496\n",
      "\n",
      "EarlyStopping counter: 1 out of 6\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6393\n",
      "Training accuracy: 0.7556\n",
      "Training weighted F1 score: 0.7101\n",
      "Training macro F1 score: 0.5802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7077\n",
      "Validation weighted F1 score: 0.6652\n",
      "Validation macro F1 score: 0.5387\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.67      0.82      0.74       176\n",
      "To some extent       0.67      0.06      0.10        71\n",
      "           Yes       0.74      0.81      0.77       249\n",
      "\n",
      "      accuracy                           0.71       496\n",
      "     macro avg       0.69      0.56      0.54       496\n",
      "  weighted avg       0.70      0.71      0.67       496\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5784\n",
      "Training accuracy: 0.7742\n",
      "Training weighted F1 score: 0.7374\n",
      "Training macro F1 score: 0.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7339\n",
      "Validation weighted F1 score: 0.7070\n",
      "Validation macro F1 score: 0.6080\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.77      0.78      0.77       176\n",
      "To some extent       0.60      0.17      0.26        71\n",
      "           Yes       0.72      0.86      0.79       249\n",
      "\n",
      "      accuracy                           0.73       496\n",
      "     macro avg       0.70      0.60      0.61       496\n",
      "  weighted avg       0.72      0.73      0.71       496\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4886\n",
      "Training accuracy: 0.8091\n",
      "Training weighted F1 score: 0.7907\n",
      "Training macro F1 score: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7097\n",
      "Validation weighted F1 score: 0.6776\n",
      "Validation macro F1 score: 0.5672\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.66      0.84      0.74       176\n",
      "To some extent       0.57      0.11      0.19        71\n",
      "           Yes       0.76      0.79      0.77       249\n",
      "\n",
      "      accuracy                           0.71       496\n",
      "     macro avg       0.66      0.58      0.57       496\n",
      "  weighted avg       0.70      0.71      0.68       496\n",
      "\n",
      "EarlyStopping counter: 1 out of 6\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4183\n",
      "Training accuracy: 0.8399\n",
      "Training weighted F1 score: 0.8272\n",
      "Training macro F1 score: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6915\n",
      "Validation weighted F1 score: 0.6836\n",
      "Validation macro F1 score: 0.6082\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.67      0.84      0.75       176\n",
      "To some extent       0.40      0.30      0.34        71\n",
      "           Yes       0.77      0.70      0.74       249\n",
      "\n",
      "      accuracy                           0.69       496\n",
      "     macro avg       0.62      0.61      0.61       496\n",
      "  weighted avg       0.69      0.69      0.68       496\n",
      "\n",
      "EarlyStopping counter: 2 out of 6\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3591\n",
      "Training accuracy: 0.8631\n",
      "Training weighted F1 score: 0.8568\n",
      "Training macro F1 score: 0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7218\n",
      "Validation weighted F1 score: 0.7034\n",
      "Validation macro F1 score: 0.6138\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.77      0.73      0.75       176\n",
      "To some extent       0.48      0.23      0.31        71\n",
      "           Yes       0.72      0.86      0.78       249\n",
      "\n",
      "      accuracy                           0.72       496\n",
      "     macro avg       0.66      0.60      0.61       496\n",
      "  weighted avg       0.70      0.72      0.70       496\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3425\n",
      "Training accuracy: 0.8763\n",
      "Training weighted F1 score: 0.8711\n",
      "Training macro F1 score: 0.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6956\n",
      "Validation weighted F1 score: 0.6948\n",
      "Validation macro F1 score: 0.6230\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.70      0.85      0.77       176\n",
      "To some extent       0.36      0.37      0.36        71\n",
      "           Yes       0.81      0.68      0.74       249\n",
      "\n",
      "      accuracy                           0.70       496\n",
      "     macro avg       0.62      0.63      0.62       496\n",
      "  weighted avg       0.71      0.70      0.69       496\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2752\n",
      "Training accuracy: 0.9035\n",
      "Training weighted F1 score: 0.9021\n",
      "Training macro F1 score: 0.8626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7077\n",
      "Validation weighted F1 score: 0.6736\n",
      "Validation macro F1 score: 0.5542\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.68      0.88      0.76       176\n",
      "To some extent       0.35      0.08      0.14        71\n",
      "           Yes       0.76      0.77      0.76       249\n",
      "\n",
      "      accuracy                           0.71       496\n",
      "     macro avg       0.60      0.58      0.55       496\n",
      "  weighted avg       0.67      0.71      0.67       496\n",
      "\n",
      "EarlyStopping counter: 1 out of 6\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2292\n",
      "Training accuracy: 0.9237\n",
      "Training weighted F1 score: 0.9207\n",
      "Training macro F1 score: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6774\n",
      "Validation weighted F1 score: 0.6571\n",
      "Validation macro F1 score: 0.5644\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.61      0.88      0.72       176\n",
      "To some extent       0.43      0.17      0.24        71\n",
      "           Yes       0.79      0.68      0.73       249\n",
      "\n",
      "      accuracy                           0.68       496\n",
      "     macro avg       0.61      0.58      0.56       496\n",
      "  weighted avg       0.67      0.68      0.66       496\n",
      "\n",
      "EarlyStopping counter: 2 out of 6\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1880\n",
      "Training accuracy: 0.9354\n",
      "Training weighted F1 score: 0.9337\n",
      "Training macro F1 score: 0.9041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6512\n",
      "Validation weighted F1 score: 0.6479\n",
      "Validation macro F1 score: 0.5859\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.60      0.88      0.71       176\n",
      "To some extent       0.37      0.35      0.36        71\n",
      "           Yes       0.84      0.58      0.69       249\n",
      "\n",
      "      accuracy                           0.65       496\n",
      "     macro avg       0.60      0.60      0.59       496\n",
      "  weighted avg       0.69      0.65      0.65       496\n",
      "\n",
      "EarlyStopping counter: 3 out of 6\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1585\n",
      "Training accuracy: 0.9525\n",
      "Training weighted F1 score: 0.9521\n",
      "Training macro F1 score: 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6935\n",
      "Validation weighted F1 score: 0.6918\n",
      "Validation macro F1 score: 0.6192\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.71      0.80      0.75       176\n",
      "To some extent       0.37      0.35      0.36        71\n",
      "           Yes       0.77      0.71      0.74       249\n",
      "\n",
      "      accuracy                           0.69       496\n",
      "     macro avg       0.62      0.62      0.62       496\n",
      "  weighted avg       0.69      0.69      0.69       496\n",
      "\n",
      "EarlyStopping counter: 4 out of 6\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1638\n",
      "Training accuracy: 0.9495\n",
      "Training weighted F1 score: 0.9491\n",
      "Training macro F1 score: 0.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6633\n",
      "Validation weighted F1 score: 0.6617\n",
      "Validation macro F1 score: 0.6061\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.62      0.86      0.72       176\n",
      "To some extent       0.40      0.41      0.40        71\n",
      "           Yes       0.83      0.59      0.69       249\n",
      "\n",
      "      accuracy                           0.66       496\n",
      "     macro avg       0.62      0.62      0.61       496\n",
      "  weighted avg       0.69      0.66      0.66       496\n",
      "\n",
      "EarlyStopping counter: 5 out of 6\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1588\n",
      "Training accuracy: 0.9530\n",
      "Training weighted F1 score: 0.9525\n",
      "Training macro F1 score: 0.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6875\n",
      "Validation weighted F1 score: 0.6658\n",
      "Validation macro F1 score: 0.5722\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.66      0.83      0.73       176\n",
      "To some extent       0.44      0.17      0.24        71\n",
      "           Yes       0.74      0.73      0.74       249\n",
      "\n",
      "      accuracy                           0.69       496\n",
      "     macro avg       0.61      0.58      0.57       496\n",
      "  weighted avg       0.67      0.69      0.67       496\n",
      "\n",
      "EarlyStopping counter: 6 out of 6\n",
      "Early stopping triggered after epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.6875\n",
      "Fold 1 weighted F1 score: 0.6658\n",
      "Fold 1 macro F1 score: 0.5722\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9395\n",
      "Training accuracy: 0.5704\n",
      "Training weighted F1 score: 0.4809\n",
      "Training macro F1 score: 0.3520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.76it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7010\n",
      "Validation weighted F1 score: 0.6550\n",
      "Validation macro F1 score: 0.4949\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.61      0.82      0.70       163\n",
      "To some extent       0.00      0.00      0.00        64\n",
      "           Yes       0.77      0.79      0.78       268\n",
      "\n",
      "      accuracy                           0.70       495\n",
      "     macro avg       0.46      0.54      0.49       495\n",
      "  weighted avg       0.62      0.70      0.65       495\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7037\n",
      "Training accuracy: 0.7183\n",
      "Training weighted F1 score: 0.6704\n",
      "Training macro F1 score: 0.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.89it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6788\n",
      "Validation weighted F1 score: 0.6371\n",
      "Validation macro F1 score: 0.4827\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.55      0.93      0.69       163\n",
      "To some extent       0.00      0.00      0.00        64\n",
      "           Yes       0.84      0.69      0.76       268\n",
      "\n",
      "      accuracy                           0.68       495\n",
      "     macro avg       0.46      0.54      0.48       495\n",
      "  weighted avg       0.64      0.68      0.64       495\n",
      "\n",
      "EarlyStopping counter: 1 out of 6\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6403\n",
      "Training accuracy: 0.7552\n",
      "Training weighted F1 score: 0.7160\n",
      "Training macro F1 score: 0.5994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6808\n",
      "Validation weighted F1 score: 0.6826\n",
      "Validation macro F1 score: 0.5804\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.68      0.86      0.76       163\n",
      "To some extent       0.23      0.25      0.24        64\n",
      "           Yes       0.82      0.68      0.74       268\n",
      "\n",
      "      accuracy                           0.68       495\n",
      "     macro avg       0.58      0.59      0.58       495\n",
      "  weighted avg       0.70      0.68      0.68       495\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5396\n",
      "Training accuracy: 0.7961\n",
      "Training weighted F1 score: 0.7726\n",
      "Training macro F1 score: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7434\n",
      "Validation weighted F1 score: 0.7074\n",
      "Validation macro F1 score: 0.5615\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.71      0.82      0.76       163\n",
      "To some extent       0.33      0.06      0.11        64\n",
      "           Yes       0.78      0.86      0.82       268\n",
      "\n",
      "      accuracy                           0.74       495\n",
      "     macro avg       0.61      0.58      0.56       495\n",
      "  weighted avg       0.70      0.74      0.71       495\n",
      "\n",
      "EarlyStopping counter: 1 out of 6\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5057\n",
      "Training accuracy: 0.8087\n",
      "Training weighted F1 score: 0.8003\n",
      "Training macro F1 score: 0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6949\n",
      "Validation weighted F1 score: 0.6850\n",
      "Validation macro F1 score: 0.5753\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.64      0.88      0.74       163\n",
      "To some extent       0.27      0.19      0.22        64\n",
      "           Yes       0.83      0.70      0.76       268\n",
      "\n",
      "      accuracy                           0.69       495\n",
      "     macro avg       0.58      0.59      0.58       495\n",
      "  weighted avg       0.70      0.69      0.69       495\n",
      "\n",
      "EarlyStopping counter: 2 out of 6\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4177\n",
      "Training accuracy: 0.8476\n",
      "Training weighted F1 score: 0.8397\n",
      "Training macro F1 score: 0.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6121\n",
      "Validation weighted F1 score: 0.5997\n",
      "Validation macro F1 score: 0.5044\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.53      0.94      0.68       163\n",
      "To some extent       0.23      0.16      0.19        64\n",
      "           Yes       0.88      0.52      0.65       268\n",
      "\n",
      "      accuracy                           0.61       495\n",
      "     macro avg       0.54      0.54      0.50       495\n",
      "  weighted avg       0.68      0.61      0.60       495\n",
      "\n",
      "EarlyStopping counter: 3 out of 6\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3843\n",
      "Training accuracy: 0.8556\n",
      "Training weighted F1 score: 0.8499\n",
      "Training macro F1 score: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6909\n",
      "Validation weighted F1 score: 0.6814\n",
      "Validation macro F1 score: 0.5726\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.64      0.90      0.75       163\n",
      "To some extent       0.26      0.19      0.22        64\n",
      "           Yes       0.84      0.68      0.75       268\n",
      "\n",
      "      accuracy                           0.69       495\n",
      "     macro avg       0.58      0.59      0.57       495\n",
      "  weighted avg       0.70      0.69      0.68       495\n",
      "\n",
      "EarlyStopping counter: 4 out of 6\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3161\n",
      "Training accuracy: 0.8900\n",
      "Training weighted F1 score: 0.8894\n",
      "Training macro F1 score: 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6848\n",
      "Validation weighted F1 score: 0.6742\n",
      "Validation macro F1 score: 0.5635\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.62      0.90      0.74       163\n",
      "To some extent       0.26      0.17      0.21        64\n",
      "           Yes       0.84      0.68      0.75       268\n",
      "\n",
      "      accuracy                           0.68       495\n",
      "     macro avg       0.57      0.58      0.56       495\n",
      "  weighted avg       0.69      0.68      0.67       495\n",
      "\n",
      "EarlyStopping counter: 5 out of 6\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2440\n",
      "Training accuracy: 0.9233\n",
      "Training weighted F1 score: 0.9221\n",
      "Training macro F1 score: 0.8933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7030\n",
      "Validation weighted F1 score: 0.6856\n",
      "Validation macro F1 score: 0.5609\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.65      0.86      0.74       163\n",
      "To some extent       0.24      0.12      0.16        64\n",
      "           Yes       0.81      0.75      0.78       268\n",
      "\n",
      "      accuracy                           0.70       495\n",
      "     macro avg       0.57      0.58      0.56       495\n",
      "  weighted avg       0.68      0.70      0.69       495\n",
      "\n",
      "EarlyStopping counter: 6 out of 6\n",
      "Early stopping triggered after epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 accuracy: 0.7030\n",
      "Fold 2 weighted F1 score: 0.6856\n",
      "Fold 2 macro F1 score: 0.5609\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9617\n",
      "Training accuracy: 0.5462\n",
      "Training weighted F1 score: 0.4835\n",
      "Training macro F1 score: 0.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.74it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6808\n",
      "Validation weighted F1 score: 0.6321\n",
      "Validation macro F1 score: 0.4846\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.57      0.89      0.70       145\n",
      "To some extent       0.00      0.00      0.00        70\n",
      "           Yes       0.77      0.74      0.76       280\n",
      "\n",
      "      accuracy                           0.68       495\n",
      "     macro avg       0.45      0.54      0.48       495\n",
      "  weighted avg       0.60      0.68      0.63       495\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7236\n",
      "Training accuracy: 0.7077\n",
      "Training weighted F1 score: 0.6532\n",
      "Training macro F1 score: 0.5155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.76it/s]\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/cfs/anaconda3/envs/pykt-hzw3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7434\n",
      "Validation weighted F1 score: 0.6875\n",
      "Validation macro F1 score: 0.5280\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.69      0.86      0.76       145\n",
      "To some extent       0.00      0.00      0.00        70\n",
      "           Yes       0.78      0.87      0.82       280\n",
      "\n",
      "      accuracy                           0.74       495\n",
      "     macro avg       0.49      0.58      0.53       495\n",
      "  weighted avg       0.64      0.74      0.69       495\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6205\n",
      "Training accuracy: 0.7617\n",
      "Training weighted F1 score: 0.7280\n",
      "Training macro F1 score: 0.6162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7374\n",
      "Validation weighted F1 score: 0.6894\n",
      "Validation macro F1 score: 0.5404\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.68      0.83      0.75       145\n",
      "To some extent       0.40      0.03      0.05        70\n",
      "           Yes       0.77      0.86      0.82       280\n",
      "\n",
      "      accuracy                           0.74       495\n",
      "     macro avg       0.62      0.58      0.54       495\n",
      "  weighted avg       0.69      0.74      0.69       495\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5430\n",
      "Training accuracy: 0.7940\n",
      "Training weighted F1 score: 0.7666\n",
      "Training macro F1 score: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7333\n",
      "Validation weighted F1 score: 0.7018\n",
      "Validation macro F1 score: 0.5744\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.68      0.86      0.76       145\n",
      "To some extent       0.37      0.10      0.16        70\n",
      "           Yes       0.79      0.83      0.81       280\n",
      "\n",
      "      accuracy                           0.73       495\n",
      "     macro avg       0.61      0.59      0.57       495\n",
      "  weighted avg       0.70      0.73      0.70       495\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4762\n",
      "Training accuracy: 0.8163\n",
      "Training weighted F1 score: 0.8041\n",
      "Training macro F1 score: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7455\n",
      "Validation weighted F1 score: 0.7060\n",
      "Validation macro F1 score: 0.5698\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.69      0.86      0.76       145\n",
      "To some extent       0.45      0.07      0.12        70\n",
      "           Yes       0.79      0.85      0.82       280\n",
      "\n",
      "      accuracy                           0.75       495\n",
      "     macro avg       0.64      0.60      0.57       495\n",
      "  weighted avg       0.71      0.75      0.71       495\n",
      "\n",
      "EarlyStopping counter: 1 out of 6\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4137\n",
      "Training accuracy: 0.8491\n",
      "Training weighted F1 score: 0.8393\n",
      "Training macro F1 score: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7131\n",
      "Validation weighted F1 score: 0.6909\n",
      "Validation macro F1 score: 0.5772\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.63      0.89      0.74       145\n",
      "To some extent       0.37      0.14      0.21        70\n",
      "           Yes       0.81      0.76      0.79       280\n",
      "\n",
      "      accuracy                           0.71       495\n",
      "     macro avg       0.60      0.60      0.58       495\n",
      "  weighted avg       0.70      0.71      0.69       495\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:43<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3771\n",
      "Training accuracy: 0.8693\n",
      "Training weighted F1 score: 0.8647\n",
      "Training macro F1 score: 0.8110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3/31 [00:00<00:04,  5.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 500\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, value \u001b[38;5;129;01min\u001b[39;00m CONFIG\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 500\u001b[0m fold_results \u001b[38;5;241m=\u001b[39m \u001b[43mperform_cross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_splits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# Save the fold results (optional)\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/cfs/huangzhiwei/BAE2025/projects/checkpoints_debertav3/fold_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[1], line 415\u001b[0m, in \u001b[0;36mperform_cross_validation\u001b[0;34m(df, n_splits, batch_size, epochs)\u001b[0m\n\u001b[1;32m    407\u001b[0m model \u001b[38;5;241m=\u001b[39m DebertaV2ForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    408\u001b[0m     CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    409\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    410\u001b[0m     hidden_dropout_prob\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    411\u001b[0m     attention_probs_dropout_prob\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    412\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Train and evaluate\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Final evaluation on validation set\u001b[39;00m\n\u001b[1;32m    424\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[1], line 309\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, device, epochs)\u001b[0m\n\u001b[1;32m    307\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m    308\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m--> 309\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    311\u001b[0m val_preds\u001b[38;5;241m.\u001b[39mextend(preds)\n\u001b[1;32m    312\u001b[0m val_true\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import DebertaV3Tokenizer, DebertaV3ForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# 添加数据文件路径到配置\n",
    "CONFIG = {\n",
    "    # 数据参数\n",
    "    'data_file': '/mnt/cfs/huangzhiwei/BAE2025/data/mrbench_v3_devset.json',            # 数据文件路径\n",
    "    \n",
    "    # 模型参数\n",
    "    'model_name': '/mnt/cfs/huangzhiwei/BAE2025/models/deberta-v3-base',  # 模型名称\n",
    "    'max_length': 512,                          # 文本最大长度\n",
    "    'dropout': 0.2,                             # dropout率\n",
    "    \n",
    "    # 训练参数\n",
    "    'learning_rate': 2e-5,                      # 学习率\n",
    "    'batch_size': 16,                           # 批次大小\n",
    "    'epochs': 40,                               # 最大训练轮次\n",
    "    'warmup_steps': 0,                          # 预热步数\n",
    "    'weight_decay': 0.01,                       # 权重衰减\n",
    "    'gradient_clip': 1.0,                       # 梯度裁剪\n",
    "    \n",
    "    # 早停参数\n",
    "    'early_stopping': True,                     # 是否启用早停\n",
    "    'patience': 6,                              # 容忍轮次\n",
    "    'min_delta': 0.001,                         # 最小改进阈值\n",
    "    'metric_for_early_stopping': 'macro_f1',    # 早停指标 ('macro_f1', 'weighted_f1', 'accuracy')\n",
    "    \n",
    "    # 交叉验证参数\n",
    "    'n_splits': 5,                              # 交叉验证折数\n",
    "    'random_state': 42,                         # 随机种子\n",
    "    \n",
    "    # 其他配置\n",
    "    'save_model': False,                        # 是否保存最佳模型\n",
    "    'model_path': '/mnt/cfs/huangzhiwei/BAE2025/projects/checkpoints_debertav3/best_model.pt',              # 模型保存路径\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 数据加载函数\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    从文件加载数据\n",
    "    \n",
    "    参数:\n",
    "        file_path: 文件路径，可以是JSON文件或包含JSON的文本文件\n",
    "        \n",
    "    返回:\n",
    "        数据列表\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    \n",
    "    # 检查文件扩展名\n",
    "    if file_path.endswith('.json'):\n",
    "        # 直接作为JSON文件读取\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                print(f\"Successfully loaded JSON data with {len(data)} entries\")\n",
    "                return data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON file: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        # 尝试从文本文件中提取JSON内容\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 尝试从文本中提取JSON数组\n",
    "        try:\n",
    "            # 查找方括号包围的内容\n",
    "            json_pattern = re.compile(r'\\[\\s*\\{.*?\\}\\s*(?:,\\s*\\.{3,}\\s*)?\\]', re.DOTALL)\n",
    "            json_match = json_pattern.search(content)\n",
    "            \n",
    "            if json_match:\n",
    "                # 替换省略号为空列表\n",
    "                json_str = json_match.group().replace('......', '[]')\n",
    "                data = json.loads(json_str)\n",
    "                print(f\"Successfully extracted JSON data from text file with {len(data)} entries\")\n",
    "                return data\n",
    "            else:\n",
    "                # 尝试解析整个文件作为JSON\n",
    "                try:\n",
    "                    data = json.loads(content)\n",
    "                    print(f\"Successfully parsed entire file as JSON with {len(data)} entries\")\n",
    "                    return data\n",
    "                except json.JSONDecodeError:\n",
    "                    raise ValueError(\"Could not extract JSON data from the input file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file: {e}\")\n",
    "            raise# 早停类\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=CONFIG['patience'], min_delta=CONFIG['min_delta'], metric=CONFIG['metric_for_early_stopping']):\n",
    "        \"\"\"\n",
    "        初始化早停机制\n",
    "        \n",
    "        参数:\n",
    "            patience: 在停止前等待的轮次数量\n",
    "            min_delta: 被视为改进的最小变化量\n",
    "            metric: 用于早停的指标 ('macro_f1', 'weighted_f1', 'accuracy')\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.metric = metric\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "        \n",
    "    def __call__(self, model, current_metrics):\n",
    "        \"\"\"\n",
    "        检查是否应该停止训练\n",
    "        \n",
    "        参数:\n",
    "            model: 当前模型\n",
    "            current_metrics: 当前评估指标字典 (包含 'accuracy', 'macro_f1', 'weighted_f1')\n",
    "            \n",
    "        返回:\n",
    "            early_stop: 是否应该停止训练\n",
    "        \"\"\"\n",
    "        score = current_metrics[self.metric]\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "            return False\n",
    "        \n",
    "        # 如果当前分数没有显著改进\n",
    "        if score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "            \n",
    "        return self.early_stop\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = load_data(CONFIG['data_file'])\n",
    "\n",
    "# Prepare dataset\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "label_map = {\"Yes\": 2, \"To some extent\": 1, \"No\": 0}\n",
    "rev_label_map = {2: \"Yes\", 1: \"To some extent\", 0: \"No\"}\n",
    "\n",
    "for item in data:\n",
    "    conversation_history = item[\"conversation_history\"]\n",
    "    \n",
    "    # Process each tutor response\n",
    "    for tutor, response_data in item[\"tutor_responses\"].items():\n",
    "        if \"annotation\" in response_data and \"Actionability\" in response_data[\"annotation\"]:\n",
    "            # Include the tutor's response as the input text\n",
    "            texts.append(response_data[\"response\"])\n",
    "            \n",
    "            # Map the guidance label to a numeric value\n",
    "            guidance_label = response_data[\"annotation\"][\"Actionability\"]\n",
    "            labels.append(label_map[guidance_label])\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    \"text\": texts,\n",
    "    \"label\": labels\n",
    "})\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Label distribution: {df['label'].value_counts().to_dict()}\")\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "class GuidanceDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=CONFIG['max_length']):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_dataloader, val_dataloader, device, epochs=CONFIG['epochs']):\n",
    "    \n",
    "    # # 首先冻结所有层\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # # 然后只解冻最后几层\n",
    "    # # 解冻分类器\n",
    "    # for param in model.classifier.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "    # # 解冻最后N个encoder层（例如最后3层）\n",
    "    # for i in range(len(model.deberta.encoder.layer) - 4, len(model.deberta.encoder.layer)):\n",
    "    #     for param in model.deberta.encoder.layer[i].parameters():\n",
    "    #         param.requires_grad = True\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), \n",
    "                     lr=CONFIG['learning_rate'], \n",
    "                     weight_decay=CONFIG['weight_decay'])\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=CONFIG['warmup_steps'], \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # 初始化最佳指标和模型状态\n",
    "    best_val_metric = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # 初始化早停机制\n",
    "    early_stopping = None\n",
    "    if CONFIG['early_stopping']:\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=CONFIG['patience'],\n",
    "            min_delta=CONFIG['min_delta'],\n",
    "            metric=CONFIG['metric_for_early_stopping']\n",
    "        )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        train_true = []\n",
    "        \n",
    "        for batch in tqdm(train_dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Get predictions for metrics\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            train_preds.extend(preds)\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['gradient_clip'])\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        train_acc = accuracy_score(train_true, train_preds)\n",
    "        train_report = classification_report(train_true, train_preds, target_names=[rev_label_map[i] for i in range(3)], output_dict=True)\n",
    "        train_f1_weighted = train_report['weighted avg']['f1-score']\n",
    "        train_f1_macro = train_report['macro avg']['f1-score']\n",
    "        \n",
    "        print(f\"Training loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Training weighted F1 score: {train_f1_weighted:.4f}\")\n",
    "        print(f\"Training macro F1 score: {train_f1_macro:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                \n",
    "                val_preds.extend(preds)\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "        val_report = classification_report(val_true, val_preds, target_names=[rev_label_map[i] for i in range(3)], output_dict=True)\n",
    "        val_f1_weighted = val_report['weighted avg']['f1-score']\n",
    "        val_f1_macro = val_report['macro avg']['f1-score']\n",
    "        \n",
    "        print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Validation weighted F1 score: {val_f1_weighted:.4f}\")\n",
    "        print(f\"Validation macro F1 score: {val_f1_macro:.4f}\")\n",
    "        print(classification_report(val_true, val_preds, target_names=[rev_label_map[i] for i in range(3)]))\n",
    "        \n",
    "        # 跟踪当前指标，用于早停和保存最佳模型\n",
    "        current_metrics = {\n",
    "            'accuracy': val_acc,\n",
    "            'weighted_f1': val_f1_weighted,\n",
    "            'macro_f1': val_f1_macro\n",
    "        }\n",
    "        \n",
    "        # 跟踪最佳模型（基于与早停相同的指标）\n",
    "        current_metric = current_metrics[CONFIG['metric_for_early_stopping']]\n",
    "        if current_metric > best_val_metric:\n",
    "            best_val_metric = current_metric\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            # 如果配置了保存模型，则保存模型\n",
    "            if CONFIG['save_model']:\n",
    "                torch.save(model.state_dict(), CONFIG['model_path'])\n",
    "                print(f\"Model saved to {CONFIG['model_path']} (best {CONFIG['metric_for_early_stopping']}: {best_val_metric:.4f})\")\n",
    "        \n",
    "        # 早停检查\n",
    "        if CONFIG['early_stopping'] and early_stopping(model, current_metrics):\n",
    "            print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "            # 恢复最佳模型状态\n",
    "            model.load_state_dict(early_stopping.best_model_state)\n",
    "            break\n",
    "    \n",
    "    # 如果训练完成但没有触发早停，确保加载最佳模型\n",
    "    if best_model_state is not None and (not CONFIG['early_stopping'] or not early_stopping.early_stop):\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Training completed. Loaded best model with {CONFIG['metric_for_early_stopping']}: {best_val_metric:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 5-fold cross-validation\n",
    "def perform_cross_validation(df, n_splits=CONFIG['n_splits'], batch_size=CONFIG['batch_size'], epochs=CONFIG['epochs']):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=CONFIG['random_state'])\n",
    "    fold_results = []\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the tokenizer\n",
    "    # tokenizer = DebertaV3Tokenizer.from_pretrained(CONFIG['model_name'])\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained(CONFIG['model_name'])\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = GuidanceDataset(\n",
    "            train_df['text'].tolist(),\n",
    "            train_df['label'].tolist(),\n",
    "            tokenizer\n",
    "        )\n",
    "        \n",
    "        val_dataset = GuidanceDataset(\n",
    "            val_df['text'].tolist(),\n",
    "            val_df['label'].tolist(),\n",
    "            tokenizer\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        # model = DebertaV3ForSequenceClassification.from_pretrained(\n",
    "        #     CONFIG['model_name'],\n",
    "        #     num_labels=3,\n",
    "        #     hidden_dropout_prob=CONFIG['dropout'],\n",
    "        #     attention_probs_dropout_prob=CONFIG['dropout']\n",
    "        # ).to(device)\n",
    "        \n",
    "        model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "            CONFIG['model_name'],\n",
    "            num_labels=3,\n",
    "            hidden_dropout_prob=CONFIG['dropout'],\n",
    "            attention_probs_dropout_prob=CONFIG['dropout']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        model = train_model(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            val_dataloader,\n",
    "            device,\n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "        # Final evaluation on validation set\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in DataLoader(val_dataset, batch_size=batch_size):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                \n",
    "                val_preds.extend(preds)\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "        fold_acc = accuracy_score(val_true, val_preds)\n",
    "        fold_report = classification_report(\n",
    "            val_true, \n",
    "            val_preds, \n",
    "            target_names=[rev_label_map[i] for i in range(3)],\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        fold_f1_weighted = fold_report['weighted avg']['f1-score']\n",
    "        fold_f1_macro = fold_report['macro avg']['f1-score']\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'accuracy': fold_acc,\n",
    "            'f1_weighted': fold_f1_weighted,\n",
    "            'f1_macro': fold_f1_macro,\n",
    "            'report': fold_report\n",
    "        })\n",
    "        \n",
    "        print(f\"Fold {fold + 1} accuracy: {fold_acc:.4f}\")\n",
    "        print(f\"Fold {fold + 1} weighted F1 score: {fold_f1_weighted:.4f}\")\n",
    "        print(f\"Fold {fold + 1} macro F1 score: {fold_f1_macro:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_acc = np.mean([result['accuracy'] for result in fold_results])\n",
    "    avg_f1_weighted = np.mean([result['f1_weighted'] for result in fold_results])\n",
    "    avg_f1_macro = np.mean([result['f1_macro'] for result in fold_results])\n",
    "    \n",
    "    print(f\"Average accuracy across {n_splits} folds: {avg_acc:.4f}\")\n",
    "    print(f\"Average weighted F1 score across {n_splits} folds: {avg_f1_weighted:.4f}\")\n",
    "    print(f\"Average macro F1 score across {n_splits} folds: {avg_f1_macro:.4f}\")\n",
    "    \n",
    "    # Calculate average per-class metrics\n",
    "    class_metrics = {label: {'precision': [], 'recall': [], 'f1-score': []} for label in rev_label_map.values()}\n",
    "    \n",
    "    for result in fold_results:\n",
    "        for label in rev_label_map.values():\n",
    "            if label in result['report']:\n",
    "                class_metrics[label]['precision'].append(result['report'][label]['precision'])\n",
    "                class_metrics[label]['recall'].append(result['report'][label]['recall'])\n",
    "                class_metrics[label]['f1-score'].append(result['report'][label]['f1-score'])\n",
    "    \n",
    "    print(\"\\nAverage per-class metrics across all folds:\")\n",
    "    for label, metrics in class_metrics.items():\n",
    "        print(f\"{label}:\")\n",
    "        for metric_name, values in metrics.items():\n",
    "            avg_value = np.mean(values) if values else 0\n",
    "            print(f\"  {metric_name}: {avg_value:.4f}\")\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "# Save processed data to CSV (optional)\n",
    "df.to_csv('/mnt/cfs/huangzhiwei/BAE2025/projects/checkpoints_debertav3/guidance_classification_data.csv', index=False)\n",
    "\n",
    "# Execute cross-validation with the specified parameters\n",
    "print(\"Starting cross-validation with the following parameters:\")\n",
    "for param, value in CONFIG.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "fold_results = perform_cross_validation(\n",
    "    df, \n",
    "    n_splits=CONFIG['n_splits'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    epochs=CONFIG['epochs']\n",
    ")\n",
    "\n",
    "# Save the fold results (optional)\n",
    "with open('/mnt/cfs/huangzhiwei/BAE2025/projects/checkpoints_debertav3/fold_results.json', 'w') as f:\n",
    "    json.dump(fold_results, f, indent=2)\n",
    "\n",
    "print(\"Classification task completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
